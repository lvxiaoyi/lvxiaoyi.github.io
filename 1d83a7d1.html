<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Hive基础-1 | 吕小医's BLOG</title><meta name="keywords" content="大数据"><meta name="author" content="lvxiaoyi"><meta name="copyright" content="lvxiaoyi"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Hive基础-1Hive基本概念视频资料和笔记资料来自尚硅谷：https:&#x2F;&#x2F;www.bilibili.com&#x2F;video&#x2F;BV1EZ4y1G7iL 什么是Hive简介Hive：由 Facebook 开源用于解决海量结构化日志的数据统计工具。 Hive 是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类 SQL 查询功能。 本质将 HQL 转化成 MapRedu">
<meta property="og:type" content="article">
<meta property="og:title" content="Hive基础-1">
<meta property="og:url" content="https://lvxiaoyi.top/1d83a7d1.html">
<meta property="og:site_name" content="吕小医&#39;s BLOG">
<meta property="og:description" content="Hive基础-1Hive基本概念视频资料和笔记资料来自尚硅谷：https:&#x2F;&#x2F;www.bilibili.com&#x2F;video&#x2F;BV1EZ4y1G7iL 什么是Hive简介Hive：由 Facebook 开源用于解决海量结构化日志的数据统计工具。 Hive 是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类 SQL 查询功能。 本质将 HQL 转化成 MapRedu">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img.lvxiaoyi.top/typora-img/image-20211028174657424.png/lvxiaoyi">
<meta property="article:published_time" content="2022-09-12T07:22:48.766Z">
<meta property="article:modified_time" content="2022-09-12T07:22:48.766Z">
<meta property="article:author" content="lvxiaoyi">
<meta property="article:tag" content="大数据">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img.lvxiaoyi.top/typora-img/image-20211028174657424.png/lvxiaoyi"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://lvxiaoyi.top/1d83a7d1"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Hive基础-1',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-09-12 15:22:48'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://p0.meituan.net/csc/8a1b1d488e6a8ab5108c9c78f36b3a1776955.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">205</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">27</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">51</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 小医</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://img.lvxiaoyi.top/typora-img/image-20211028174657424.png/lvxiaoyi')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">吕小医's BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 小医</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Hive基础-1</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-09-12T07:22:48.766Z" title="发表于 2022-09-12 15:22:48">2022-09-12</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-09-12T07:22:48.766Z" title="更新于 2022-09-12 15:22:48">2022-09-12</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/">hadoop</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Hive基础-1"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Hive基础-1"><a href="#Hive基础-1" class="headerlink" title="Hive基础-1"></a>Hive基础-1</h1><h1 id="Hive基本概念"><a href="#Hive基本概念" class="headerlink" title="Hive基本概念"></a>Hive基本概念</h1><p>视频资料和笔记资料来自尚硅谷：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1EZ4y1G7iL">https://www.bilibili.com/video/BV1EZ4y1G7iL</a></p>
<h2 id="什么是Hive"><a href="#什么是Hive" class="headerlink" title="什么是Hive"></a>什么是Hive</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>Hive：由 Facebook 开源用于解决海量结构化日志的数据统计工具。</p>
<p>Hive 是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类 SQL 查询功能。</p>
<h3 id="本质"><a href="#本质" class="headerlink" title="本质"></a>本质</h3><p>将 HQL 转化成 MapReduce 程序</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/202111051408924.png/lvxiaoyi" alt="image-20211105140828918" style="zoom: 50%;" />

<ol>
<li><p>Hive 处理的数据存储在 HDFS</p>
</li>
<li><p>Hive 分析数据底层的实现是 MapReduce</p>
</li>
<li><p>执行程序运行在 Yarn 上</p>
</li>
</ol>
<h2 id="Hive-的优缺点"><a href="#Hive-的优缺点" class="headerlink" title="Hive 的优缺点"></a>Hive 的优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ol>
<li><p>操作接口采用类 SQL 语法，提供快速开发的能力（简单、容易上手）</p>
</li>
<li><p>避免了去写 MapReduce，减少开发人员的学习成本。 </p>
</li>
<li><p>Hive 的执行延迟比较高，因此 Hive 常用于数据分析，对实时性要求不高的场合。 </p>
</li>
<li><p>Hive 优势在于处理大数据，对于处理小数据没有优势，因为 Hive 的执行延迟比较高。</p>
</li>
<li><p>Hive 支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。</p>
</li>
</ol>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ol>
<li><p>Hive 的 HQL 表达能力有限</p>
<ol>
<li><p>迭代式算法无法表达</p>
</li>
<li><p>数据挖掘方面不擅长，由于 MapReduce 数据处理流程的限制，效率更高的算法却无法实现。</p>
</li>
</ol>
</li>
<li><p>Hive 的效率比较低</p>
<ol>
<li>Hive 自动生成的 MapReduce 作业，通常情况下不够智能化</li>
<li>Hive 调优比较困难，粒度较粗</li>
</ol>
</li>
</ol>
<h2 id="Hive-架构原理"><a href="#Hive-架构原理" class="headerlink" title="Hive 架构原理"></a>Hive 架构原理</h2><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/202111051412897.png/lvxiaoyi" alt="image-20211105141211806" style="zoom: 33%;" />

<ol>
<li><p>用户接口：Client</p>
<p>CLI（command-line interface）、JDBC/ODBC(jdbc 访问 hive)、WEBUI（浏览器访问 hive）</p>
</li>
<li><p>元数据：Metastore</p>
<p>元数据包括：表名、表所属的数据库（默认是 default）、表的拥有者、列/分区字段、表的类型（是否是外部表）、表的数据所在目录等；</p>
<p>默认存储在自带的 derby 数据库中，推荐使用 MySQL 存储 Metastore</p>
</li>
<li><p>Hadoop</p>
<p>使用 HDFS 进行存储，使用 MapReduce 进行计算</p>
</li>
<li><p>驱动器：Driver</p>
<ol>
<li><p>解析器（SQL Parser）：将 SQL 字符串转换成抽象语法树 AST，这一步一般都用第三方工具库完成，比如 antlr；对 AST 进行语法分析，比如表是否存在、字段是否存在、SQL语义是否有误。</p>
</li>
<li><p>编译器（Physical Plan）：将 AST 编译生成逻辑执行计划。</p>
</li>
<li><p>优化器（Query Optimizer）：对逻辑执行计划进行优化。</p>
</li>
<li><p>执行器（Execution）：把逻辑执行计划转换成可以运行的物理计划。对于 Hive 来说，就是 MR/Spark。</p>
</li>
</ol>
</li>
</ol>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/202111051415518.png/lvxiaoyi" style="zoom:50%;" />

<p>Hive 通过给用户提供的一系列交互接口，接收到用户的指令(SQL)，使用自己的 Driver，结合元数据(MetaStore)，将这些指令翻译成 MapReduce，提交到 Hadoop 中执行，最后，将执行返回的结果输出到用户交互接口。</p>
<h2 id="Hive-和数据库比较"><a href="#Hive-和数据库比较" class="headerlink" title="Hive 和数据库比较"></a>Hive 和数据库比较</h2><p>由于 Hive 采用了类似 SQL 的查询语言 HQL(Hive Query Language)，因此很容易将 Hive 理解为数据库。其实从结构上来看，Hive 和数据库除了拥有类似的查询语言，再无类似之处。本文将从多个方面来阐述 Hive 和数据库的差异。数据库可以用在 Online 的应用中，但是Hive 是为数据仓库而设计的，清楚这一点，有助于从应用角度理解 Hive 的特性。</p>
<h3 id="查询语言"><a href="#查询语言" class="headerlink" title="查询语言"></a>查询语言</h3><p>由于 SQL 被广泛的应用在数据仓库中，因此，专门针对 Hive 的特性设计了类 SQL 的查询语言 HQL。熟悉 SQL 开发的开发者可以很方便的使用 Hive 进行开发。</p>
<h3 id="数据更新"><a href="#数据更新" class="headerlink" title="数据更新"></a>数据更新</h3><p>由于 Hive 是针对数据仓库应用设计的，而数据仓库的内容是读多写少的。因此，Hive 中 不建议对数据的改写，所有的数据都是在加载的时候确定好的。而数据库中的数据通常是需要经常进行修改的，因此可以使用 INSERT INTO … VALUES 添加数据，使用 UPDATE … SET 修改数据。</p>
<h3 id="执行延迟"><a href="#执行延迟" class="headerlink" title="执行延迟"></a>执行延迟</h3><p>Hive 在查询数据的时候，由于没有索引，需要扫描整个表，因此延迟较高。另外一个导致 Hive 执行延迟高的因素是 MapReduce 框架。由于 MapReduce 本身具有较高的延迟，因此在利用 MapReduce 执行 Hive 查询时，也会有较高的延迟。相对的，数据库的执行延迟较低。当然，这个低是有条件的，即数据规模较小，当数据规模大到超过数据库的处理能力的时候，Hive 的并行计算显然能体现出优势。</p>
<h3 id="数据规模"><a href="#数据规模" class="headerlink" title="数据规模"></a>数据规模</h3><p>由于 Hive 建立在集群上并可以利用 MapReduce 进行并行计算，因此可以支持很大规模的数据；对应的，数据库可以支持的数据规模较小</p>
<h1 id="Hive-安装"><a href="#Hive-安装" class="headerlink" title="Hive 安装"></a>Hive 安装</h1><h2 id="Hive-安装地址"><a href="#Hive-安装地址" class="headerlink" title="Hive 安装地址"></a>Hive 安装地址</h2><ol>
<li>Hive 官网地址：<a target="_blank" rel="noopener" href="http://hive.apache.org/">http://hive.apache.org/</a></li>
<li>文档查看地址：<a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted">https://cwiki.apache.org/confluence/display/Hive/GettingStarted</a></li>
<li>下载地址：<a target="_blank" rel="noopener" href="http://archive.apache.org/dist/hive/">http://archive.apache.org/dist/hive/</a></li>
<li>github 地址：<a target="_blank" rel="noopener" href="https://github.com/apache/hive">https://github.com/apache/hive</a></li>
</ol>
<h2 id="Hive-安装部署"><a href="#Hive-安装部署" class="headerlink" title="Hive 安装部署"></a>Hive 安装部署</h2><h3 id="安装-Hive"><a href="#安装-Hive" class="headerlink" title="安装 Hive"></a>安装 Hive</h3><ol>
<li></li>
<li><p>把 apache-hive-3.1.2-bin.tar.gz 上传到 linux 的/opt/software 目录下</p>
</li>
<li><p>解压 apache-hive-3.1.2-bin.tar.gz 到/opt/module/目录下面</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hive]$ tar -zxvf /opt/software/hive/apache-hive-3.1.2-bin.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure></li>
<li><p>修改 apache-hive-3.1.2-bin.tar.gz 的名称为 hive</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hive]$ mv /opt/module/apache-hive-3.1.2-bin/ /opt/module/hive</span><br></pre></td></tr></table></figure></li>
<li><p>修改/etc/profile.d/my_env.sh，添加环境变量</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 software]$ sudo vim /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure></li>
<li><p>添加内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#HIVE_HOME</span><br><span class="line">export HIVE_HOME=/opt/module/hive</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br></pre></td></tr></table></figure>

<p>刷新环境变量</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile.d/my_env.sh </span><br></pre></td></tr></table></figure></li>
<li><p>解决日志 Jar 包冲突</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 software]$ mv $HIVE_HOME/lib/log4j-slf4j-impl-2.10.0.jar $HIVE_HOME/lib/log4j-slf4j-impl-2.10.0.bak</span><br></pre></td></tr></table></figure></li>
<li><p>初始化元数据库（使用hive自带的derby）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hive]$ bin/schematool -dbType derby -initSchema</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="启动并使用-Hive"><a href="#启动并使用-Hive" class="headerlink" title="启动并使用 Hive"></a>启动并使用 Hive</h3><ol>
<li><p>启动 Hive</p>
<p>前提：启动了hadoop</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hive]$ myhadoop.sh start</span><br></pre></td></tr></table></figure>

<p>启动hive：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hive]$ bin/hive</span><br></pre></td></tr></table></figure></li>
<li><p>使用 Hive</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show databases;</span><br><span class="line">hive&gt; show tables;</span><br><span class="line">hive&gt; create table test(id int);</span><br><span class="line">hive&gt; insert into test values(1);</span><br><span class="line">....</span><br><span class="line">Total MapReduce CPU Time Spent: 51 seconds 580 msec</span><br><span class="line">OK</span><br><span class="line">Time taken: 142.49 seconds</span><br><span class="line">hive&gt; select * from test;</span><br></pre></td></tr></table></figure>

<p>查看：<a target="_blank" rel="noopener" href="http://hadoop102:9870/explorer.html#/user/hive/warehouse/test">http://hadoop102:9870/explorer.html#/user/hive/warehouse/test</a></p>
</li>
<li><p>在 CRT 窗口中开启另一个窗口开启 Hive，在/tmp/lvxiaoyi 目录下监控 hive.log 文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Caused by: ERROR XSDB6: Another instance of Derby may have already booted </span><br><span class="line">the database /opt/module/hive/metastore_db.</span><br><span class="line"> at </span><br><span class="line">org.apache.derby.iapi.error.StandardException.newException(Unknown </span><br><span class="line">Source)</span><br><span class="line"> at </span><br><span class="line">org.apache.derby.iapi.error.StandardException.newException(Unknown Source)</span><br><span class="line"> at </span><br><span class="line">org.apache.derby.impl.store.raw.data.BaseDataFileFactory.privGetJBMSLockO</span><br><span class="line">nDB(Unknown Source)</span><br><span class="line"> at </span><br><span class="line">org.apache.derby.impl.store.raw.data.BaseDataFileFactory.run(Unknown </span><br><span class="line">Source)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>原因在于 Hive 默认使用的元数据库为 derby，开启 Hive 之后就会占用元数据库，且不与其他客户端共享数据，所以我们需要将 Hive 的元数据地址改为 MySQL</p>
</li>
</ol>
<h2 id="MySQL-安装"><a href="#MySQL-安装" class="headerlink" title="MySQL 安装"></a>MySQL 安装</h2><ol>
<li><p>检查当前系统是否安装过 MySQL</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ rpm -qa|grep mariadb</span><br><span class="line">mariadb-libs-5.5.56-2.el7.x86_64 </span><br><span class="line">//如果存在通过如下命令卸载</span><br><span class="line">[lvxiaoyi @hadoop102 ~]$ sudo rpm -e --nodeps mariadb-libs</span><br></pre></td></tr></table></figure></li>
<li><p>将 MySQL 安装包拷贝到/opt/software/hive 目录下</p>
<p>下载地址：<a target="_blank" rel="noopener" href="https://cdn.mysql.com/archives/mysql-5.7/mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar">https://cdn.mysql.com/archives/mysql-5.7/mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi @hadoop102 hive]# ll</span><br><span class="line">-rw-rw-r--. 1 lvxiaoyi lvxiaoyi 609556480 11月 13 15:25 mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar</span><br></pre></td></tr></table></figure></li>
<li><p>解压 MySQL 安装包</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hive]$ tar -xf mysql-5.7.28-1.el7.x86_64.rpm-bundle.tar</span><br></pre></td></tr></table></figure></li>
<li><p>在安装目录下执行 rpm 安装</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi @hadoop102 hive]$ </span><br><span class="line">sudo rpm -ivh mysql-community-common-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">sudo rpm -ivh mysql-community-libs-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">sudo rpm -ivh mysql-community-libs-compat-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">sudo rpm -ivh mysql-community-client-5.7.28-1.el7.x86_64.rpm</span><br><span class="line">sudo rpm -ivh mysql-community-server-5.7.28-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure>

<p>注意:按照顺序依次执行</p>
<p>如果 Linux 是最小化安装的，在安装 mysql-community-server-5.7.28-1.el7.x86_64.rpm 时</p>
<p>可能会出现如下错误</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 software]$ sudo rpm -ivh mysql-community-server-</span><br><span class="line">5.7.28-1.el7.x86_64.rpm</span><br><span class="line">警告：mysql-community-server-5.7.28-1.el7.x86_64.rpm: 头 V3 DSA/SHA1 </span><br><span class="line">Signature, 密钥 ID 5072e1f5: NOKEY</span><br><span class="line">错误：依赖检测失败：</span><br><span class="line"> libaio.so.1()(64bit) 被 mysql-community-server-5.7.28-1.el7.x86_64 </span><br><span class="line">需要</span><br><span class="line"> libaio.so.1(LIBAIO_0.1)(64bit) 被 mysql-community-server-5.7.28-</span><br><span class="line">1.el7.x86_64 需要</span><br><span class="line"> libaio.so.1(LIBAIO_0.4)(64bit) 被 mysql-community-server-5.7.28-</span><br><span class="line">1.el7.x86_64 需要</span><br></pre></td></tr></table></figure>

<p>通过 yum 安装缺少的依赖,然后重新安装 mysql-community-server-5.7.28-1.el7.x86_64 即 可</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hive] yum install -y libaio</span><br></pre></td></tr></table></figure></li>
<li><p>删除/etc/my.cnf 文件中 datadir 指向的目录下的所有内容,如果有内容的情况下:</p>
<p>查看 datadir 的值：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">datadir=/var/lib/mysql</span><br></pre></td></tr></table></figure>

<p>删除/var/lib/mysql 目录下的所有内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi @hadoop102 mysql]# cd /var/lib/mysql</span><br><span class="line">[lvxiaoyi @hadoop102 mysql]# sudo rm -rf ./* //注意执行命令的位置</span><br></pre></td></tr></table></figure></li>
<li><p>初始化数据库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi @hadoop102 opt]$ sudo mysqld --initialize --user=mysql</span><br></pre></td></tr></table></figure></li>
<li><p>查看临时生成的 root 用户的密码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi @hadoop102 opt]$ sudo cat /var/log/mysqld.log</span><br></pre></td></tr></table></figure></li>
<li><p>启动 MySQL 服务</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi @hadoop102 opt]$ sudo systemctl start mysqld</span><br></pre></td></tr></table></figure></li>
<li><p>登录 MySQL 数据库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi @hadoop102 opt]$ mysql -uroot -p</span><br><span class="line">Enter password: 输入临时生成的密码</span><br></pre></td></tr></table></figure>

<p>登录成功</p>
</li>
<li><p>必须先修改 root 用户的密码,否则执行其他的操作会报错</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set password = password(&quot;123456&quot;);</span><br></pre></td></tr></table></figure></li>
<li><p>修改 mysql 库下的 user 表中的 root 用户允许任意 ip 连接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; update mysql.user set host=&#x27;%&#x27; where user=&#x27;root&#x27;;</span><br><span class="line">mysql&gt; flush privileges;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="Hive-元数据配置到-MySQL"><a href="#Hive-元数据配置到-MySQL" class="headerlink" title="Hive 元数据配置到 MySQL"></a>Hive 元数据配置到 MySQL</h2><h3 id="拷贝驱动"><a href="#拷贝驱动" class="headerlink" title="拷贝驱动"></a>拷贝驱动</h3><p>将 MySQL 的 JDBC 驱动拷贝到 Hive 的 lib 目录下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 software]$ cp /opt/software/hive/mysql-connector-java-5.1.37.jar $HIVE_HOME/lib</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="配置-Metastore-到-MySQL"><a href="#配置-Metastore-到-MySQL" class="headerlink" title="配置 Metastore 到 MySQL"></a>配置 Metastore 到 MySQL</h3><ol>
<li><p>在$HIVE_HOME/conf 目录下新建 hive-site.xml 文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 software]$ vim $HIVE_HOME/conf/hive-site.xml</span><br></pre></td></tr></table></figure>

<p>添加如下内容</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- jdbc 连接的 URL --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://hadoop102:3306/metastore?useSSL=false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- jdbc 连接的 Driver--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- jdbc 连接的 username--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>root<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- jdbc 连接的 password --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>123456<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Hive 元数据存储版本的验证 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.schema.verification<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--元数据存储授权--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.event.db.notification.api.auth<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- Hive 默认在 HDFS 的工作目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/user/hive/warehouse<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>登陆 MySQL</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 software]$ mysql -uroot -p123456</span><br></pre></td></tr></table></figure></li>
<li><p>新建 Hive 元数据库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; create database metastore;</span><br><span class="line">mysql&gt; quit;</span><br></pre></td></tr></table></figure></li>
<li><p>初始化 Hive 元数据库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 software]$ schematool -initSchema -dbType mysql -verbose</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="再次启动-Hive"><a href="#再次启动-Hive" class="headerlink" title="再次启动 Hive"></a>再次启动 Hive</h3><ol>
<li><p>启动 Hive</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hive]$ bin/hive</span><br></pre></td></tr></table></figure></li>
<li><p>使用 Hive</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show databases;</span><br><span class="line">hive&gt; show tables;</span><br><span class="line">hive&gt; create table test (id int);</span><br><span class="line">hive&gt; insert into test values(1);</span><br><span class="line">...</span><br><span class="line">Total MapReduce CPU Time Spent: 34 seconds 480 msec</span><br><span class="line">OK</span><br><span class="line">Time taken: 99.062 seconds</span><br><span class="line"></span><br><span class="line">hive&gt; select * from test;</span><br></pre></td></tr></table></figure></li>
<li><p>在 CRT 窗口中开启另一个窗口开启 Hive</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show databases;</span><br><span class="line">hive&gt; show tables;</span><br><span class="line">hive&gt; select * from aa;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="使用元数据服务的方式访问-Hive"><a href="#使用元数据服务的方式访问-Hive" class="headerlink" title="使用元数据服务的方式访问 Hive"></a>使用元数据服务的方式访问 Hive</h2><ol>
<li><p>在 hive-site.xml 文件中添加如下配置信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hive]$ vim $HIVE_HOME/conf/hive-site.xml</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定存储元数据要连接的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.metastore.uris<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">value</span>&gt;</span>thrift://hadoop102:9083<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>启动 metastore</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop202 hive]$ hive --service metastore</span><br><span class="line">2020-04-24 16:58:08: Starting Hive Metastore Server</span><br><span class="line">注意: 启动后窗口不能再操作，需打开一个新的 shell 窗口做别的操作</span><br></pre></td></tr></table></figure></li>
<li><p>启动 hive</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop202 hive]$ bin/hive</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="使用-JDBC-方式访问-Hive"><a href="#使用-JDBC-方式访问-Hive" class="headerlink" title="使用 JDBC 方式访问 Hive"></a>使用 JDBC 方式访问 Hive</h2><ol>
<li><p>在 hive-site.xml 文件中添加如下配置信息</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 指定 hiveserver2 连接的 host --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定 hiveserver2 连接的端口号 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.server2.thrift.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>10000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>启动 hiveserver2</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hive]$ bin/hive --service hiveserver2</span><br></pre></td></tr></table></figure></li>
<li><p>启动 beeline 客户端（需要多等待一会）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hive]$ bin/beeline -u jdbc:hive2://hadoop102:10000 -n </span><br><span class="line">lvxiaoyi</span><br></pre></td></tr></table></figure></li>
<li><p>看到如下界面</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Connecting to jdbc:hive2://hadoop102:10000</span><br><span class="line">Connected to: Apache Hive (version 3.1.2)</span><br><span class="line">Driver: Hive JDBC (version 3.1.2)</span><br><span class="line">Transaction isolation: TRANSACTION_REPEATABLE_READ</span><br><span class="line">Beeline version 3.1.2 by Apache Hive</span><br><span class="line">0: jdbc:hive2://hadoop102:10000&gt;</span><br></pre></td></tr></table></figure></li>
<li><p>编写 hive 服务启动脚本（了解）</p>
<ol>
<li><p>前台启动的方式导致需要打开多个 shell 窗口，可以使用如下方式后台方式启动</p>
<p>nohup: 放在命令开头，表示不挂起,也就是关闭终端进程也继续保持运行状态</p>
<p>/dev/null：是 Linux 文件系统中的一个文件，被称为黑洞，所有写入改文件的内容都会被自动丢弃</p>
<p>2&gt;&amp;1 : 表示将错误重定向到标准输出上</p>
<p>&amp;: 放在命令结尾,表示后台运行</p>
<p>一般会组合使用: nohup [xxx 命令操作]&gt; file 2&gt;&amp;1 &amp;，表示将 xxx 命令运行的结果输出到 file 中，并保持命令启动的进程在后台运行。</p>
<p>如上命令不要求掌握</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop202 hive]$ nohup hive --service metastore 2&gt;&amp;1 &amp;</span><br><span class="line">[lvxiaoyi@hadoop202 hive]$ nohup hive --service hiveserver2 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure></li>
<li><p>为了方便使用，可以直接编写脚本来管理服务的启动和关闭</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hive]$ vim $HIVE_HOME/bin/hiveservices.sh</span><br></pre></td></tr></table></figure>

<p>内容如下：此脚本的编写不要求掌握。直接拿来使用即可。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">HIVE_LOG_DIR=<span class="variable">$HIVE_HOME</span>/logs</span><br><span class="line"><span class="keyword">if</span> [ ! -d <span class="variable">$HIVE_LOG_DIR</span> ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">	mkdir -p <span class="variable">$HIVE_LOG_DIR</span></span><br><span class="line"><span class="keyword">fi</span><span class="comment">#检查进程是否运行正常，参数 1 为进程名，参数 2 为进程端口</span></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">check_process</span></span>()</span><br><span class="line">&#123;</span><br><span class="line"> 	pid=$(ps -ef 2&gt;/dev/null | grep -v grep | grep -i <span class="variable">$1</span> | awk <span class="string">&#x27;&#123;print </span></span><br><span class="line"><span class="string">$2&#125;&#x27;</span>)</span><br><span class="line"> 	ppid=$(netstat -nltp 2&gt;/dev/null | grep <span class="variable">$2</span> | awk <span class="string">&#x27;&#123;print $7&#125;&#x27;</span> | cut -</span><br><span class="line">d <span class="string">&#x27;/&#x27;</span> -f 1)</span><br><span class="line"> <span class="built_in">echo</span> <span class="variable">$pid</span></span><br><span class="line"> 	[[ <span class="string">&quot;<span class="variable">$pid</span>&quot;</span> =~ <span class="string">&quot;<span class="variable">$ppid</span>&quot;</span> ]] &amp;&amp; [ <span class="string">&quot;<span class="variable">$ppid</span>&quot;</span> ] &amp;&amp; <span class="built_in">return</span> 0 || <span class="built_in">return</span> 1</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">hive_start</span></span>()</span><br><span class="line">&#123;</span><br><span class="line"> 	metapid=$(check_process HiveMetastore 9083)</span><br><span class="line"> 	cmd=<span class="string">&quot;nohup hive --service metastore &gt;<span class="variable">$HIVE_LOG_DIR</span>/metastore.log 2&gt;&amp;1 </span></span><br><span class="line"><span class="string">&amp;&quot;</span></span><br><span class="line"> 	[ -z <span class="string">&quot;<span class="variable">$metapid</span>&quot;</span> ] &amp;&amp; <span class="built_in">eval</span> <span class="variable">$cmd</span> || <span class="built_in">echo</span> <span class="string">&quot;Metastroe 服务已启动&quot;</span></span><br><span class="line"> 	server2pid=$(check_process HiveServer2 10000)</span><br><span class="line">	cmd=<span class="string">&quot;nohup hiveserver2 &gt;<span class="variable">$HIVE_LOG_DIR</span>/hiveServer2.log 2&gt;&amp;1 &amp;&quot;</span></span><br><span class="line"> 	[ -z <span class="string">&quot;<span class="variable">$server2pid</span>&quot;</span> ] &amp;&amp; <span class="built_in">eval</span> <span class="variable">$cmd</span> || <span class="built_in">echo</span> <span class="string">&quot;HiveServer2 服务已启动&quot;</span> &#125;</span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">hive_stop</span></span>()</span><br><span class="line">&#123;</span><br><span class="line">	metapid=$(check_process HiveMetastore 9083)</span><br><span class="line">	 [ <span class="string">&quot;<span class="variable">$metapid</span>&quot;</span> ] &amp;&amp; <span class="built_in">kill</span> <span class="variable">$metapid</span> || <span class="built_in">echo</span> <span class="string">&quot;Metastore 服务未启动&quot;</span></span><br><span class="line">	 server2pid=$(check_process HiveServer2 10000)</span><br><span class="line">	 [ <span class="string">&quot;<span class="variable">$server2pid</span>&quot;</span> ] &amp;&amp; <span class="built_in">kill</span> <span class="variable">$server2pid</span> || <span class="built_in">echo</span> <span class="string">&quot;HiveServer2 服务未启动&quot;</span> &#125;</span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">&quot;start&quot;</span>)</span><br><span class="line"> 	hive_start</span><br><span class="line"> 	;;</span><br><span class="line"><span class="string">&quot;stop&quot;</span>)</span><br><span class="line"> 	hive_stop</span><br><span class="line"> 	;;</span><br><span class="line"><span class="string">&quot;restart&quot;</span>)</span><br><span class="line"> 	hive_stop</span><br><span class="line">	 sleep 2</span><br><span class="line"> 	hive_start</span><br><span class="line"> 	;;</span><br><span class="line"><span class="string">&quot;status&quot;</span>)</span><br><span class="line"> 	check_process HiveMetastore 9083 &gt;/dev/null &amp;&amp; <span class="built_in">echo</span> <span class="string">&quot;Metastore 服务运行正常&quot;</span> || <span class="built_in">echo</span> <span class="string">&quot;Metastore 服务运行异常&quot;</span></span><br><span class="line"> 	check_process HiveServer2 10000 &gt;/dev/null &amp;&amp; <span class="built_in">echo</span> <span class="string">&quot;HiveServer2 服务运行正常&quot;</span> || <span class="built_in">echo</span> <span class="string">&quot;HiveServer2 服务运行异常&quot;</span></span><br><span class="line">	 ;;</span><br><span class="line">*)</span><br><span class="line">	 <span class="built_in">echo</span> Invalid Args!</span><br><span class="line">	 <span class="built_in">echo</span> <span class="string">&#x27;Usage: &#x27;</span>$(basename <span class="variable">$0</span>)<span class="string">&#x27; start|stop|restart|status&#x27;</span></span><br><span class="line">	 ;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure></li>
<li><p>添加执行权限</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hive]$ chmod +x $HIVE_HOME/bin/hiveservices.sh</span><br></pre></td></tr></table></figure></li>
<li><p>启动 Hive 后台服务</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hive]$ hiveservices.sh start</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h2 id="Hive-常用交互命令"><a href="#Hive-常用交互命令" class="headerlink" title="Hive 常用交互命令"></a>Hive 常用交互命令</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hive]$ bin/hive -help</span><br></pre></td></tr></table></figure>

<ol>
<li><p>“-e”不进入 hive 的交互窗口执行 sql 语句</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hive]$ bin/hive -e &quot;select id from test;&quot;</span><br><span class="line">...</span><br><span class="line">Hive Session ID = a44d284a-659c-449b-a485-11250b7ddbb8</span><br><span class="line">OK</span><br><span class="line">1</span><br><span class="line">1</span><br><span class="line">Time taken: 9.05 seconds, Fetched: 2 row(s)</span><br></pre></td></tr></table></figure></li>
<li><p>“-f”执行脚本中 sql 语句</p>
<ol>
<li><p>在/opt/module/hive/下创建 datas 目录并在 datas 目录下创建 hivef.sql 文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 datas]$ touch hivef.sql</span><br></pre></td></tr></table></figure></li>
<li><p>文件中写入正确的 sql 语句</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select id from test;</span><br></pre></td></tr></table></figure></li>
<li><p>执行文件中的 sql 语句</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hive]$ bin/hive -f /opt/module/hive/datas/hivef.sql</span><br></pre></td></tr></table></figure></li>
<li><p>执行文件中的 sql 语句并将结果写入文件中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hive]$ bin/hive -f /opt/module/hive/datas/hivef.sql &gt; /opt/module/datas/hive_result.txt</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h2 id="Hive-其他命令操作"><a href="#Hive-其他命令操作" class="headerlink" title="Hive 其他命令操作"></a>Hive 其他命令操作</h2><ol>
<li><p>退出 hive 窗口：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive(default)&gt;exit;</span><br><span class="line">hive(default)&gt;quit;</span><br></pre></td></tr></table></figure></li>
<li><p>在 hive cli 命令窗口中如何查看 hdfs 文件系统</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive(default)&gt;dfs -ls /;</span><br></pre></td></tr></table></figure></li>
<li><p>查看在 hive 中输入的所有历史命令</p>
<ol>
<li><p>进入到当前用户的根目录 /root 或/home/lvxiaoyi</p>
</li>
<li><p>查看. hivehistory 文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi]@hadoop102 ~]$ cat .hivehistory</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h2 id="Hive-常见属性配置"><a href="#Hive-常见属性配置" class="headerlink" title="Hive 常见属性配置"></a>Hive 常见属性配置</h2><h3 id="Hive-运行日志信息配置"><a href="#Hive-运行日志信息配置" class="headerlink" title="Hive 运行日志信息配置"></a>Hive 运行日志信息配置</h3><ol>
<li><p>Hive 的 log 默认存放在/tmp/lvxiaoyi/hive.log 目录下（当前用户名下）</p>
</li>
<li><p>修改 hive 的 log 存放日志到/opt/module/hive/logs</p>
<ol>
<li><p>修改/opt/module/hive/conf/hive-log4j2.properties.template 文件名称为hive-log4j2.properties</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 conf]$ pwd</span><br><span class="line">/opt/module/hive/conf</span><br><span class="line">[lvxiaoyi@hadoop102 conf]$ mv hive-log4j2.properties.template hive.log4j2.properties</span><br></pre></td></tr></table></figure></li>
<li><p>在 hive-log4j2.properties 文件中修改 log 存放位置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">property.hive.log.dir = /opt/module/hive/logs</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h3 id="打印-当前库-和-表头"><a href="#打印-当前库-和-表头" class="headerlink" title="打印 当前库 和 表头"></a>打印 当前库 和 表头</h3><p>在 hive-site.xml 中加入如下两个配置:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.header<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hive.cli.print.current.db<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h3 id="参数配置方式"><a href="#参数配置方式" class="headerlink" title="参数配置方式"></a>参数配置方式</h3><ol>
<li><p>查看当前所有的配置信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt;set;</span><br></pre></td></tr></table></figure></li>
<li><p>参数的配置三种方式</p>
<ol>
<li><p>配置文件方式</p>
<p>默认配置文件：hive-default.xml</p>
<p>用户自定义配置文件：hive-site.xml</p>
<p>注意：用户自定义配置会覆盖默认配置。另外，Hive 也会读入 Hadoop 的配置，因为 Hive是作为 Hadoop 的客户端启动的，Hive 的配置会覆盖 Hadoop 的配置。配置文件的设定对本机启动的所有 Hive 进程都有效。</p>
</li>
<li><p>命令行参数方式</p>
<p>启动 Hive 时，可以在命令行添加-hiveconf param=value 来设定参数。</p>
<p>例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop103 hive]$ bin/hive -hiveconf mapred.reduce.tasks=10;</span><br></pre></td></tr></table></figure>

<p>注意：仅对本次 hive 启动有效</p>
<p>查看参数设置：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapred.reduce.tasks;</span><br></pre></td></tr></table></figure></li>
<li><p>参数声明方式</p>
<p>可以在 HQL 中使用 SET 关键字设定参数</p>
<p>例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapred.reduce.tasks=100;</span><br></pre></td></tr></table></figure>

<p>注意：仅对本次 hive 启动有效。</p>
<p>查看参数设置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapred.reduce.tasks;</span><br></pre></td></tr></table></figure></li>
</ol>
<p>上述三种设定方式的优先级依次递增。即配置文件&lt;命令行参数&lt;参数声明。注意某些系统级的参数，例如 log4j 相关的设定，必须用前两种方式设定，因为那些参数的读取在会话建立以前已经完成了。</p>
</li>
</ol>
<h1 id="Hive-数据类型"><a href="#Hive-数据类型" class="headerlink" title="Hive 数据类型"></a>Hive 数据类型</h1><h2 id="基本数据类型"><a href="#基本数据类型" class="headerlink" title="基本数据类型"></a>基本数据类型</h2><table>
<thead>
<tr>
<th>Hive数据类型</th>
<th>Java数据类型</th>
<th>长度</th>
<th>例子</th>
</tr>
</thead>
<tbody><tr>
<td>TINYINT</td>
<td>byte</td>
<td>1byte 有符号整数</td>
<td>20</td>
</tr>
<tr>
<td>SMALINT</td>
<td>short</td>
<td>2byte 有符号整数</td>
<td>20</td>
</tr>
<tr>
<td>INT</td>
<td>int</td>
<td>4byte 有符号整数</td>
<td>20</td>
</tr>
<tr>
<td>BIGINT</td>
<td>long</td>
<td>8byte 有符号整数</td>
<td>20</td>
</tr>
<tr>
<td>BOOLEAN</td>
<td>boolean</td>
<td>布尔类型，true 或者false</td>
<td>TRUE FALSE</td>
</tr>
<tr>
<td>FLOAT</td>
<td>float</td>
<td>单精度浮点数</td>
<td>3.14159</td>
</tr>
<tr>
<td>DOUBLE</td>
<td>double</td>
<td>双精度浮点数</td>
<td>3.14159</td>
</tr>
<tr>
<td>STRING</td>
<td>string</td>
<td>字符系列。可以指定字符集。可以使用单引号或者双引号。</td>
<td>‘ now is the time ’<br /> “for all good men”</td>
</tr>
<tr>
<td>TIMESTAMP</td>
<td></td>
<td>时间类型</td>
<td></td>
</tr>
<tr>
<td>BINARY</td>
<td></td>
<td>字节数组</td>
<td></td>
</tr>
</tbody></table>
<p>对于 Hive 的 String 类型相当于数据库的 varchar 类型，该类型是一个可变的字符串，不过它不能声明其中最多能存储多少个字符，理论上它可以存储 2GB 的字符数。</p>
<h2 id="集合数据类型"><a href="#集合数据类型" class="headerlink" title="集合数据类型"></a>集合数据类型</h2><table>
<thead>
<tr>
<th>数据类型</th>
<th>描述</th>
<th>语法示例</th>
</tr>
</thead>
<tbody><tr>
<td>STRUCT</td>
<td>和 c 语言中的 struct 类似，都可以通过“点”符号访问元素内容。例如，如果某个列的数据类型是 STRUCT{first  STRING, last STRING},那么第 1 个元素可以通过字段.first 来</td>
<td>struct()<br/>例 如 struct&lt;street:string, city:string&gt;</td>
</tr>
<tr>
<td>MAP</td>
<td>MAP 是一组键-值对元组集合，使用数组表示法可以访问数据。例如，如果某个列的数据类型是 MAP，其中键–&gt;值对是’first’-&gt;’John’和’last’-&gt;’Doe’，那么可以通过字段名[‘last’]获取最后一个元素</td>
<td>map()<br/>例如 map&lt;string, int&gt;</td>
</tr>
<tr>
<td>ARRAY</td>
<td>数组是一组具有相同类型和名称的变量的集合。这些变量称为数组的元素，每个数组元素都有一个编号，编号从零开始。例如，数组值为[‘John’, ‘Doe’]，那么第 2 个元素可以通过数组名[1]进行引用。</td>
<td>Array()<br />例如  <code>array&lt;string&gt;</code></td>
</tr>
</tbody></table>
<p>Hive 有三种复杂数据类型 ARRAY、MAP 和 STRUCT。ARRAY 和 MAP 与 Java 中的 Array和 Map 类似，而 STRUCT 与 C 语言中的 Struct 类似，它封装了一个命名字段集合，复杂数据类型允许任意层次的嵌套。</p>
<ol>
<li><p>案例实操</p>
<ol>
<li><p>假设某表有如下一行，我们用 JSON 格式来表示其数据结构。在 Hive 下访问的格式为</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> <span class="attr">&quot;name&quot;</span>: <span class="string">&quot;songsong&quot;</span>,</span><br><span class="line"> <span class="attr">&quot;friends&quot;</span>: [<span class="string">&quot;bingbing&quot;</span> , <span class="string">&quot;lili&quot;</span>] , <span class="comment">//列表 Array, </span></span><br><span class="line"> <span class="attr">&quot;children&quot;</span>: &#123; <span class="comment">//键值 Map,</span></span><br><span class="line"> 	<span class="attr">&quot;xiao song&quot;</span>: <span class="number">18</span> ,</span><br><span class="line"> 	<span class="attr">&quot;xiaoxiao song&quot;</span>: <span class="number">19</span></span><br><span class="line"> &#125;</span><br><span class="line"> <span class="string">&quot;address&quot;</span>: &#123; <span class="comment">//结构 Struct,</span></span><br><span class="line"> 	<span class="attr">&quot;street&quot;</span>: <span class="string">&quot;hui long guan&quot;</span>,</span><br><span class="line"> 	<span class="attr">&quot;city&quot;</span>: <span class="string">&quot;beijing&quot;</span></span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>基于上述数据结构，我们在 Hive 里创建对应的表，并导入数据。</p>
<p>创建本地测试文件 test.txt</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">songsong,bingbing_lili,xiao song:18_xiaoxiao song:19,hui long guan_beijing</span><br><span class="line">yangyang,caicai_susu,xiao yang:18_xiaoxiao yang:19,chao yang_beijing</span><br></pre></td></tr></table></figure>

<p>注意：MAP，STRUCT 和 ARRAY 里的元素间关系都可以用同一个字符表示，这里用“_”。 </p>
</li>
<li><p>Hive 上创建测试表 test</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">create table test(</span><br><span class="line">name string,</span><br><span class="line">friends array&lt;string&gt;,</span><br><span class="line">children map&lt;string, int&gt;,</span><br><span class="line">address struct&lt;street:string, city:string&gt; )</span><br><span class="line">row format delimited fields terminated by &#x27;,&#x27;</span><br><span class="line">collection items terminated by &#x27;_&#x27;</span><br><span class="line">map keys terminated by &#x27;:&#x27;</span><br><span class="line">lines terminated by &#x27;\n&#x27;;</span><br></pre></td></tr></table></figure>

<p>字段解释：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">row format delimited fields terminated by &#x27;,&#x27; -- 列分隔符</span><br><span class="line">collection items terminated by &#x27;_&#x27; 			--MAP STRUCT 和 ARRAY 的分隔符(数据分割符号)</span><br><span class="line">map keys terminated by &#x27;:&#x27; 					-- MAP 中的 key 与 value 的分隔符</span><br><span class="line">lines terminated by &#x27;\n&#x27;; 					-- 行分隔符</span><br></pre></td></tr></table></figure></li>
<li><p>导入文本数据到测试表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &#x27;/opt/module/hive/datas/test.txt&#x27; into table test;</span><br></pre></td></tr></table></figure></li>
<li><p>访问三种集合列里的数据，以下分别是 ARRAY，MAP，STRUCT 的访问方式</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select friends[1],children[&#x27;xiao song&#x27;],address.city from test where name=&quot;songsong&quot;;</span><br><span class="line">OK</span><br><span class="line">_c0 _c1 city</span><br><span class="line">lili 18 beijing</span><br><span class="line">Time taken: 0.076 seconds, Fetched: 1 row(s)</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h2 id="类型转化"><a href="#类型转化" class="headerlink" title="类型转化"></a>类型转化</h2><p>Hive 的原子数据类型是可以进行隐式转换的，类似于 Java 的类型转换，例如某表达式使用 INT 类型，TINYINT 会自动转换为 INT 类型，但是 Hive 不会进行反向转化，例如，某表达式使用 TINYINT 类型，INT 不会自动转换为 TINYINT 类型，它会返回错误，除非使用 CAST操作</p>
<ol>
<li><p>隐式类型转换规则如下</p>
<ol>
<li><p>任何整数类型都可以隐式地转换为一个范围更广的类型，如 TINYINT 可以转换成INT，INT 可以转换成 BIGINT。 </p>
</li>
<li><p>所有整数类型、FLOAT 和 STRING 类型都可以隐式地转换成 DOUBLE。 </p>
</li>
<li><p>TINYINT、SMALLINT、INT 都可以转换为 FLOAT。 </p>
</li>
<li><p>BOOLEAN 类型不可以转换为任何其它的类型。</p>
</li>
</ol>
</li>
<li><p>可以使用 CAST 操作显示进行数据类型转换</p>
<p>例如 CAST(‘1’ AS INT)将把字符串’1’ 转换成整数 1；如果强制类型转换失败，如执行CAST(‘X’ AS INT)，表达式返回空值 NULL。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">0: jdbc:hive2://hadoop102:10000&gt; select &#x27;1&#x27;+2, cast(&#x27;1&#x27;as int) + 2;</span><br><span class="line">+------+------+--+</span><br><span class="line">| _c0 | _c1 |</span><br><span class="line">+------+------+--+</span><br><span class="line">| 3.0 | 3 |</span><br><span class="line">+------+------+--+</span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="DDL-数据定义"><a href="#DDL-数据定义" class="headerlink" title="DDL 数据定义"></a>DDL 数据定义</h1><h2 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CREATE DATABASE [IF NOT EXISTS] database_name</span><br><span class="line">[COMMENT database_comment]</span><br><span class="line">[LOCATION hdfs_path]</span><br><span class="line">[WITH DBPROPERTIES (property_name=property_value, ...)];</span><br></pre></td></tr></table></figure>

<ol>
<li><p>创建一个数据库，数据库在 HDFS 上的默认存储路径是/user/hive/warehouse/*.db</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; create database db_hive;</span><br></pre></td></tr></table></figure></li>
<li><p>避免要创建的数据库已经存在错误，增加 if not exists 判断。（标准写法）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; create database db_hive;</span><br><span class="line">FAILED: Execution Error, return code 1 from </span><br><span class="line">org.apache.hadoop.hive.ql.exec.DDLTask. Database db_hive already exists</span><br><span class="line">hive (default)&gt; create database if not exists db_hive;</span><br></pre></td></tr></table></figure></li>
<li><p>创建一个数据库，指定数据库在 HDFS 上存放的位置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; create database db_hive2 location &#x27;/db_hive2.db&#x27;;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="查询数据库"><a href="#查询数据库" class="headerlink" title="查询数据库"></a>查询数据库</h2><h3 id="显示数据库"><a href="#显示数据库" class="headerlink" title="显示数据库"></a>显示数据库</h3><ol>
<li><p>显示数据库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show databases;</span><br></pre></td></tr></table></figure></li>
<li><p>过滤显示查询的数据库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show databases like &#x27;db_hive*&#x27;;</span><br><span class="line">OK</span><br><span class="line">db_hive</span><br><span class="line">db_hive_1</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h3 id="查看数据库详情"><a href="#查看数据库详情" class="headerlink" title="查看数据库详情"></a>查看数据库详情</h3><ol>
<li><p>显示数据库信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; desc database db_hive;</span><br><span class="line">OK</span><br><span class="line">db_hive hdfs://hadoop102:9820/user/hive/warehouse/db_hive.db</span><br><span class="line">lvxiaoyiUSER</span><br></pre></td></tr></table></figure></li>
<li><p>显示数据库详细信息，extended</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; desc database db_hive;</span><br><span class="line">OK</span><br><span class="line">db_name	comment	location	owner_name	owner_type	parameters</span><br><span class="line">db_hive		hdfs://hadoop102:8020/user/hive/warehouse/db_hive.db	lvxiaoyi	USER	</span><br><span class="line">Time taken: 0.037 seconds, Fetched: 1 row(s)</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="切换当前数据库"><a href="#切换当前数据库" class="headerlink" title="切换当前数据库"></a>切换当前数据库</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; use db_hive;</span><br></pre></td></tr></table></figure>

<h2 id="修改数据库"><a href="#修改数据库" class="headerlink" title="修改数据库"></a>修改数据库</h2><p>用户可以使用 ALTER DATABASE 命令为某个数据库的 DBPROPERTIES 设置键-值对属性值，来描述这个数据库的属性信息。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; alter database db_hive </span><br><span class="line">set dbproperties(&#x27;createtime&#x27;=&#x27;20170830&#x27;);</span><br></pre></td></tr></table></figure>

<p>在 hive 中查看修改结果</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; desc database extended db_hive;</span><br><span class="line">db_name comment location owner_name owner_type parameters</span><br><span class="line">db_hive hdfs://hadoop102:9820/user/hive/warehouse/db_hive.db </span><br><span class="line">lvxiaoyi USER &#123;createtime=20170830&#125;</span><br></pre></td></tr></table></figure>

<h2 id="删除数据库"><a href="#删除数据库" class="headerlink" title="删除数据库"></a>删除数据库</h2><ol>
<li><p>删除空数据库</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt;drop database db_hive2;</span><br></pre></td></tr></table></figure></li>
<li><p>如果删除的数据库不存在，最好采用 if exists 判断数据库是否存在</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; drop database db_hive;</span><br><span class="line">FAILED: SemanticException [Error 10072]: Database does not exist: db_hive</span><br><span class="line">hive&gt; drop database if exists db_hive2;</span><br></pre></td></tr></table></figure></li>
<li><p>如果数据库不为空，可以采用 cascade 命令，强制删除</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; drop database db_hive;</span><br><span class="line">FAILED: Execution Error, return code 1 from </span><br><span class="line">org.apache.hadoop.hive.ql.exec.DDLTask. </span><br><span class="line">InvalidOperationException(message:Database db_hive is not empty. One or </span><br><span class="line">more tables exist.)</span><br><span class="line">hive&gt; drop database db_hive cascade;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="创建表"><a href="#创建表" class="headerlink" title="创建表"></a>创建表</h2><ol>
<li><p>建表语法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name</span><br><span class="line">[(col_name data_type [COMMENT col_comment], ...)]</span><br><span class="line">[COMMENT table_comment]</span><br><span class="line">[PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]</span><br><span class="line">[CLUSTERED BY (col_name, col_name, ...)</span><br><span class="line">[SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS]</span><br><span class="line">[ROW FORMAT row_format]</span><br><span class="line">[STORED AS file_format]</span><br><span class="line">[LOCATION hdfs_path]</span><br><span class="line">[TBLPROPERTIES (property_name=property_value, ...)]</span><br><span class="line">[AS select_statement]</span><br></pre></td></tr></table></figure></li>
<li><p>字段解释说明</p>
<ol>
<li><p>CREATE TABLE 创建一个指定名字的表。如果相同名字的表已经存在，则抛出异常；用户可以用 IF NOT EXISTS 选项来忽略这个异常。</p>
</li>
<li><p>EXTERNAL 关键字可以让用户创建一个外部表，在建表的同时可以指定一个指向实际数据的路径（LOCATION），在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据。 </p>
</li>
<li><p>COMMENT：为表和列添加注释。</p>
</li>
<li><p>PARTITIONED BY 创建分区表</p>
</li>
<li><p>CLUSTERED BY 创建分桶表</p>
</li>
<li><p>SORTED BY 不常用，对桶中的一个或多个列另外排序</p>
</li>
<li><p>ROW FORMAT </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">DELIMITED [FIELDS TERMINATED BY char] [COLLECTION ITEMS TERMINATED BY char]</span><br><span class="line"> [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]</span><br><span class="line"> | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, </span><br><span class="line">property_name=property_value, ...)]</span><br></pre></td></tr></table></figure>

<p>用户在建表的时候可以自定义 SerDe 或者使用自带的 SerDe。如果没有指定 ROW FORMAT 或者 ROW FORMAT DELIMITED，将会使用自带的 SerDe。在建表的时候，用户还需要为表指定列，用户在指定表的列的同时也会指定自定义的 SerDe，Hive 通过 SerDe 确定表的具体的列的数据。</p>
<p>SerDe 是 Serialize/Deserilize 的简称， hive 使用 Serde 进行行对象的序列与反序列化。</p>
</li>
<li><p>STORED AS 指定存储文件类型</p>
<p>常用的存储文件类型：SEQUENCEFILE（二进制序列文件）、TEXTFILE（文本）、RCFILE（列式存储格式文件）</p>
<p>如果文件数据是纯文本，可以使用STORED AS TEXTFILE。如果数据需要压缩，使用 STORED AS SEQUENCEFILE。 </p>
</li>
<li><p>LOCATION ：指定表在 HDFS 上的存储位置。</p>
</li>
<li><p>AS：后跟查询语句，根据查询结果创建表。</p>
</li>
<li><p>LIKE 允许用户复制现有的表结构，但是不复制数据。</p>
</li>
</ol>
</li>
</ol>
<h3 id="管理表"><a href="#管理表" class="headerlink" title="管理表"></a>管理表</h3><ol>
<li><p>理论</p>
<p>默认创建的表都是所谓的管理表，有时也被称为内部表。因为这种表，Hive 会（或多或少地）控制着数据的生命周期。Hive 默认情况下会将这些表的数据存储在由配置项hive.metastore.warehouse.dir(例如，/user/hive/warehouse)所定义的目录的子目录下。</p>
<p> 管理表不适合和其他工具共享数据。</p>
</li>
<li><p>案例实操</p>
<ol start="0">
<li>原始数据</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">1001 ss1</span><br><span class="line">1002 ss2</span><br><span class="line">1003 ss3</span><br><span class="line">1004 ss4</span><br><span class="line">1005 ss5</span><br><span class="line">1006 ss6</span><br><span class="line">1007 ss7</span><br><span class="line">1008 ss8</span><br><span class="line">1009 ss9</span><br><span class="line">1010 ss10</span><br><span class="line">1011 ss11</span><br><span class="line">1012 ss12</span><br><span class="line">1013 ss13</span><br><span class="line">1014 ss14</span><br><span class="line">1015 ss15</span><br><span class="line">1016 ss16</span><br></pre></td></tr></table></figure>

<ol>
<li><p>普通创建表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">create table if not exists student(</span><br><span class="line">id int, name string</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;</span><br><span class="line">stored as textfile</span><br><span class="line">location &#x27;/user/hive/warehouse/student&#x27;;</span><br></pre></td></tr></table></figure></li>
<li><p>根据查询结果创建表（查询的结果会添加到新创建的表中）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create table if not exists student2 as select id, name from student;</span><br></pre></td></tr></table></figure></li>
<li><p>根据已经存在的表结构创建表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create table if not exists student3 like student;</span><br></pre></td></tr></table></figure></li>
<li><p>查询表的类型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; desc formatted student2;</span><br><span class="line">Table Type: MANAGED_TABLE</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h3 id="外部表"><a href="#外部表" class="headerlink" title="外部表"></a>外部表</h3><ol>
<li><p>理论</p>
<p>因为表是外部表，所以 Hive 并非认为其完全拥有这份数据。删除该表并不会删除掉这份数据，不过描述表的元数据信息会被删除掉</p>
</li>
<li><p>管理表和外部表的使用场景</p>
<p>每天将收集到的网站日志定期流入 HDFS 文本文件。在外部表（原始日志表）的基础上做大量的统计分析，用到的中间表、结果表使用内部表存储，数据通过 SELECT+INSERT 进入内部表。</p>
</li>
<li><p>案例实操</p>
<p>分别创建部门和员工外部表，并向表中导入数据。</p>
<ol start="0">
<li><p>原始数据</p>
<p>dept:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">10 ACCOUNTING 1700</span><br><span class="line">20 RESEARCH 1800</span><br><span class="line">30 SALES 1900</span><br><span class="line">40 OPERATIONS 1700</span><br></pre></td></tr></table></figure>

<p>emp：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">7369 SMITH CLERK 7902 1980-12-17 800.00 20</span><br><span class="line">7499 ALLEN SALESMAN 7698 1981-2-20 1600.00 300.00 30</span><br><span class="line">7521 WARD SALESMAN 7698 1981-2-22 1250.00 500.00 30</span><br><span class="line">7566 JONES MANAGER 7839 1981-4-2 2975.00 20</span><br><span class="line">7654 MARTIN SALESMAN 7698 1981-9-28 1250.00 1400.00 30</span><br><span class="line">7698 BLAKE MANAGER 7839 1981-5-1 2850.00 30</span><br><span class="line">7782 CLARK MANAGER 7839 1981-6-9 2450.00 10</span><br><span class="line">7788 SCOTT ANALYST 7566 1987-4-19 3000.00 20</span><br><span class="line">7839 KING PRESIDENT 1981-11-17 5000.00 10</span><br><span class="line">7844 TURNER SALESMAN 7698 1981-9-8 1500.00 0.00 30</span><br><span class="line">7876 ADAMS CLERK 7788 1987-5-23 1100.00 20</span><br><span class="line">7900 JAMES CLERK 7698 1981-12-3 950.00 30</span><br><span class="line">7902 FORD ANALYST 7566 1981-12-3 3000.00 20</span><br><span class="line">7934 MILLER CLERK 7782 1982-1-23 1300.00 10</span><br></pre></td></tr></table></figure></li>
<li><p>上传数据到 HDFS</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; dfs -mkdir /student;</span><br><span class="line">hive (default)&gt; dfs -put /opt/module/datas/student.txt /student;</span><br></pre></td></tr></table></figure></li>
<li><p>建表语句，创建外部表</p>
<p>创建部门表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">create external table if not exists dept(</span><br><span class="line">deptno int,</span><br><span class="line">dname string,</span><br><span class="line">loc int</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>

<p>创建员工表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">create external table if not exists emp(</span><br><span class="line">empno int,</span><br><span class="line">ename string,</span><br><span class="line">job string,</span><br><span class="line">mgr int,</span><br><span class="line">hiredate string,</span><br><span class="line">sal double,</span><br><span class="line">comm double,</span><br><span class="line">deptno int)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure></li>
<li><p>查看创建的表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt;show tables;</span><br></pre></td></tr></table></figure></li>
<li><p>查看表格式化数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; desc formatted dept;</span><br><span class="line">Table Type: EXTERNAL_TABLE</span><br></pre></td></tr></table></figure></li>
<li><p>删除外部表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; drop table dept;</span><br></pre></td></tr></table></figure>

<p>外部表删除后，hdfs 中的数据还在，但是 metadata 中 dept 的元数据已被删除</p>
</li>
</ol>
</li>
</ol>
<h3 id="管理表与外部表的互相转换"><a href="#管理表与外部表的互相转换" class="headerlink" title="管理表与外部表的互相转换"></a>管理表与外部表的互相转换</h3><ol>
<li><p>查询表的类型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; desc formatted student2;</span><br><span class="line">Table Type: MANAGED_TABLE</span><br></pre></td></tr></table></figure></li>
<li><p>修改内部表 student2 为外部表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table student2 set tblproperties(&#x27;EXTERNAL&#x27;=&#x27;TRUE&#x27;);</span><br></pre></td></tr></table></figure></li>
<li><p>查询表的类型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; desc formatted student2;</span><br><span class="line">Table Type: EXTERNAL_TABLE</span><br></pre></td></tr></table></figure></li>
<li><p>修改外部表 student2 为内部表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table student2 set tblproperties(&#x27;EXTERNAL&#x27;=&#x27;FALSE&#x27;);</span><br></pre></td></tr></table></figure></li>
<li><p>查询表的类型</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; desc formatted student2;</span><br><span class="line">Table Type: MANAGED_TABLE</span><br></pre></td></tr></table></figure>

<p>注意：(‘EXTERNAL’=’TRUE’)和(‘EXTERNAL’=’FALSE’)为固定写法，区分大小写！ </p>
</li>
</ol>
<h2 id="修改表"><a href="#修改表" class="headerlink" title="修改表"></a>修改表</h2><h3 id="重命名表"><a href="#重命名表" class="headerlink" title="重命名表"></a>重命名表</h3><ol>
<li><p>语法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE table_name RENAME TO new_table_name</span><br></pre></td></tr></table></figure></li>
<li><p>实操案例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; alter table dept_partition2 rename to dept_partition3;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="增加、修改和删除表分区"><a href="#增加、修改和删除表分区" class="headerlink" title="增加、修改和删除表分区"></a>增加、修改和删除表分区</h3><p>看第七章</p>
<h3 id="增加-修改-替换列信息"><a href="#增加-修改-替换列信息" class="headerlink" title="增加/修改/替换列信息"></a>增加/修改/替换列信息</h3><h4 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h4><ol>
<li><p>更新列</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE table_name CHANGE [COLUMN] col_old_name col_new_name </span><br><span class="line">column_type [COMMENT col_comment] [FIRST|AFTER column_name]</span><br></pre></td></tr></table></figure></li>
<li><p>增加和替换列</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE table_name ADD|REPLACE COLUMNS (col_name data_type [COMMENT </span><br><span class="line">col_comment], ...)</span><br></pre></td></tr></table></figure>

<p>注：ADD 是代表新增一字段，字段位置在所有列后面(partition 列前)，REPLACE 则是表示替换表中所有字段。</p>
</li>
</ol>
<h4 id="实操案例"><a href="#实操案例" class="headerlink" title="实操案例"></a>实操案例</h4><ol>
<li><p>查询表结构</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; desc dept;</span><br></pre></td></tr></table></figure></li>
<li><p>添加列</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; alter table dept add columns(deptdesc string);</span><br></pre></td></tr></table></figure></li>
<li><p>查询表结构</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; desc dept;</span><br></pre></td></tr></table></figure></li>
<li><p>更新列</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; alter table dept change column deptdesc desc string;</span><br></pre></td></tr></table></figure></li>
<li><p>查询表结构</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; desc dept;</span><br></pre></td></tr></table></figure></li>
<li><p>替换列</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; alter table dept replace columns(deptno string, dname</span><br><span class="line">string, loc string);</span><br></pre></td></tr></table></figure></li>
<li><p>查询表结构</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; desc dept;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; drop table dept;</span><br></pre></td></tr></table></figure>

<h1 id="DML-数据操作"><a href="#DML-数据操作" class="headerlink" title="DML 数据操作"></a>DML 数据操作</h1><h2 id="数据导入"><a href="#数据导入" class="headerlink" title="数据导入"></a>数据导入</h2><h3 id="向表中装载数据（Load）"><a href="#向表中装载数据（Load）" class="headerlink" title="向表中装载数据（Load）"></a>向表中装载数据（Load）</h3><h4 id="语法-1"><a href="#语法-1" class="headerlink" title="语法"></a>语法</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; load data [local] inpath &#x27;数据的 path&#x27; [overwrite] into table </span><br><span class="line">student [partition (partcol1=val1,…)]</span><br></pre></td></tr></table></figure>

<ol>
<li><p>load data:表示加载数据</p>
</li>
<li><p>local:表示从本地加载数据到 hive 表；否则从 HDFS 加载数据到 hive 表 </p>
</li>
<li><p>inpath:表示加载数据的路径</p>
</li>
<li><p>overwrite:表示覆盖表中已有数据，否则表示追加</p>
</li>
<li><p>into table:表示加载到哪张表</p>
</li>
<li><p>student:表示具体的表</p>
</li>
<li><p>partition:表示上传到指定分区</p>
</li>
</ol>
<h4 id="实操案例-1"><a href="#实操案例-1" class="headerlink" title="实操案例"></a>实操案例</h4><ol start="0">
<li><p>创建一张表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; create table student(id string, name string) row format </span><br><span class="line">delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure></li>
<li><p>加载本地文件到 hive</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath </span><br><span class="line">&#x27;/opt/module/hive/datas/student.txt&#x27; into table default.student;</span><br></pre></td></tr></table></figure></li>
<li><p>加载 HDFS 文件到 hive 中</p>
<p>上传文件到 HDFS</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; dfs -put /opt/module/hive/data/student.txt </span><br><span class="line">/user/lvxiaoyi/hive;</span><br></pre></td></tr></table></figure>

<p>加载 HDFS 上数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data inpath &#x27;/user/lvxiaoyi/hive/student.txt&#x27; into </span><br><span class="line">table default.student;</span><br></pre></td></tr></table></figure></li>
<li><p>加载数据覆盖表中已有的数据</p>
<p>上传文件到 HDFS</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; dfs -put /opt/module/data/student.txt /user/lvxiaoyi/hive;</span><br></pre></td></tr></table></figure>

<p>加载数据覆盖表中已有的数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data inpath &#x27;/user/lvxiaoyi/hive/student.txt&#x27; </span><br><span class="line">overwrite into table default.student;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="通过查询语句向表中插入数据（Insert）"><a href="#通过查询语句向表中插入数据（Insert）" class="headerlink" title="通过查询语句向表中插入数据（Insert）"></a>通过查询语句向表中插入数据（Insert）</h3><ol>
<li><p>创建一张表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; create table student_par(id int, name string) row format </span><br><span class="line">delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure></li>
<li><p>基本插入数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert into table student_par </span><br><span class="line">values(1,&#x27;wangwu&#x27;),(2,&#x27;zhaoliu&#x27;);</span><br></pre></td></tr></table></figure></li>
<li><p>基本模式插入（根据单张表查询结果）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert overwrite table student_par</span><br><span class="line"> select id, name from student where month=&#x27;201709&#x27;;</span><br></pre></td></tr></table></figure>

<p>insert into：以追加数据的方式插入到表或分区，原有数据不会删除</p>
<p>insert overwrite：会覆盖表中已存在的数据</p>
<p>注意：insert 不支持插入部分字段</p>
</li>
<li><p>多表（多分区）插入模式（根据多张表查询结果）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; from student</span><br><span class="line"> insert overwrite table student partition(month=&#x27;201707&#x27;)</span><br><span class="line"> select id, name where month=&#x27;201709&#x27;</span><br><span class="line"> insert overwrite table student partition(month=&#x27;201706&#x27;)</span><br><span class="line"> select id, name where month=&#x27;201709&#x27;;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="查询语句中创建表并加载数据（As-Select）"><a href="#查询语句中创建表并加载数据（As-Select）" class="headerlink" title="查询语句中创建表并加载数据（As Select）"></a>查询语句中创建表并加载数据（As Select）</h3><p>根据查询结果创建表（查询的结果会添加到新创建的表中）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">create table if not exists student3</span><br><span class="line">as select id, name from student;</span><br></pre></td></tr></table></figure>

<h3 id="创建表时通过-Location-指定加载数据路径"><a href="#创建表时通过-Location-指定加载数据路径" class="headerlink" title="创建表时通过 Location 指定加载数据路径"></a>创建表时通过 Location 指定加载数据路径</h3><ol>
<li><p>上传数据到 hdfs 上</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; dfs -mkdir /student;</span><br><span class="line">hive (default)&gt; dfs -put /opt/module/datas/student.txt /student;</span><br></pre></td></tr></table></figure></li>
<li><p>创建表，并指定在 hdfs 上的位置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; create external table if not exists student5(</span><br><span class="line"> id int, name string</span><br><span class="line"> )</span><br><span class="line"> row format delimited fields terminated by &#x27;\t&#x27;</span><br><span class="line"> location &#x27;/student</span><br></pre></td></tr></table></figure></li>
<li><p>查询数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from student5;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="Import-数据到指定-Hive-表中"><a href="#Import-数据到指定-Hive-表中" class="headerlink" title="Import 数据到指定 Hive 表中"></a>Import 数据到指定 Hive 表中</h3><p>注意：先用 export 导出后，再将数据导入</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; import table student2</span><br><span class="line">from &#x27;/user/hive/warehouse/export/student&#x27;;</span><br></pre></td></tr></table></figure>

<h2 id="数据导出"><a href="#数据导出" class="headerlink" title="数据导出"></a>数据导出</h2><h3 id="Insert-导出"><a href="#Insert-导出" class="headerlink" title="Insert 导出"></a>Insert 导出</h3><ol>
<li><p>将查询的结果导出到本地</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert overwrite local directory </span><br><span class="line">&#x27;/opt/module/hive/data/export/student&#x27;</span><br><span class="line">select * from student;</span><br></pre></td></tr></table></figure></li>
<li><p>将查询的结果格式化导出到本地</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive(default)&gt;insert overwrite local directory </span><br><span class="line">&#x27;/opt/module/hive/data/export/student1&#x27;</span><br><span class="line">ROW FORMAT DELIMITED FIELDS TERMINATED BY &#x27;\t&#x27;</span><br><span class="line">select * from student;</span><br></pre></td></tr></table></figure></li>
<li><p>将查询的结果导出到 HDFS 上(没有 local)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert overwrite directory &#x27;/user/lvxiaoyi/student2&#x27;</span><br><span class="line"> ROW FORMAT DELIMITED FIELDS TERMINATED BY &#x27;\t&#x27; </span><br><span class="line"> select * from student;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="Hadoop-命令导出到本地"><a href="#Hadoop-命令导出到本地" class="headerlink" title="Hadoop 命令导出到本地"></a>Hadoop 命令导出到本地</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; dfs -get /user/hive/warehouse/student/student.txt</span><br><span class="line">/opt/module/data/export/student3.txt;</span><br></pre></td></tr></table></figure>

<h3 id="Hive-Shell-命令导出"><a href="#Hive-Shell-命令导出" class="headerlink" title="Hive Shell 命令导出"></a>Hive Shell 命令导出</h3><p>基本语法：（hive -f/-e 执行语句或者脚本 &gt; file）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hive]$ bin/hive -e &#x27;select * from default.student;&#x27; &gt;</span><br><span class="line">/opt/module/hive/data/export/student4.txt;</span><br></pre></td></tr></table></figure>

<h3 id="Export-导出到-HDFS-上"><a href="#Export-导出到-HDFS-上" class="headerlink" title="Export 导出到 HDFS 上"></a>Export 导出到 HDFS 上</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(defahiveult)&gt; export table default.student </span><br><span class="line">to &#x27;/user/hive/warehouse/export/student&#x27;;</span><br></pre></td></tr></table></figure>

<p>export 和 import 主要用于两个 Hadoop 平台集群之间 Hive 表迁移。</p>
<h3 id="Sqoop-导出"><a href="#Sqoop-导出" class="headerlink" title="Sqoop 导出"></a>Sqoop 导出</h3><p>后面章节</p>
<h3 id="清除表中数据（Truncate）"><a href="#清除表中数据（Truncate）" class="headerlink" title="清除表中数据（Truncate）"></a>清除表中数据（Truncate）</h3><p>注意：Truncate 只能删除管理表，不能删除外部表中数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; truncate table student;</span><br></pre></td></tr></table></figure>

<h1 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h1><p><a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Select">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Select</a></p>
<p>查询语句语法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">SELECT [ALL | DISTINCT] select_expr, select_expr, ...</span><br><span class="line">FROM table_reference</span><br><span class="line">[WHERE where_condition]</span><br><span class="line">[GROUP BY col_list]</span><br><span class="line">[ORDER BY col_list]</span><br><span class="line">[CLUSTER BY col_list</span><br><span class="line">| [DISTRIBUTE BY col_list] [SORT BY col_list]</span><br><span class="line">]</span><br><span class="line">[LIMIT number]</span><br></pre></td></tr></table></figure>

<h2 id="基本查询（Select…From）"><a href="#基本查询（Select…From）" class="headerlink" title="基本查询（Select…From）"></a>基本查询（Select…From）</h2><h3 id="全表和特定列查询"><a href="#全表和特定列查询" class="headerlink" title="全表和特定列查询"></a>全表和特定列查询</h3><ol start="0">
<li><p>数据准备</p>
<ol start="0">
<li><p>原始数据</p>
<p>dept:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">10 ACCOUNTING 1700</span><br><span class="line">20 RESEARCH 1800</span><br><span class="line">30 SALES 1900</span><br><span class="line">40 OPERATIONS 1700</span><br></pre></td></tr></table></figure>

<p>emp：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">7369 SMITH CLERK 7902 1980-12-17 800.00 20</span><br><span class="line">7499 ALLEN SALESMAN 7698 1981-2-20 1600.00 300.00 30</span><br><span class="line">7521 WARD SALESMAN 7698 1981-2-22 1250.00 500.00 30</span><br><span class="line">7566 JONES MANAGER 7839 1981-4-2 2975.00 20</span><br><span class="line">7654 MARTIN SALESMAN 7698 1981-9-28 1250.00 1400.00 30</span><br><span class="line">7698 BLAKE MANAGER 7839 1981-5-1 2850.00 30</span><br><span class="line">7782 CLARK MANAGER 7839 1981-6-9 2450.00 10</span><br><span class="line">7788 SCOTT ANALYST 7566 1987-4-19 3000.00 20</span><br><span class="line">7839 KING PRESIDENT 1981-11-17 5000.00 10</span><br><span class="line">7844 TURNER SALESMAN 7698 1981-9-8 1500.00 0.00 30</span><br><span class="line">7876 ADAMS CLERK 7788 1987-5-23 1100.00 20</span><br><span class="line">7900 JAMES CLERK 7698 1981-12-3 950.00 30</span><br><span class="line">7902 FORD ANALYST 7566 1981-12-3 3000.00 20</span><br><span class="line">7934 MILLER CLERK 7782 1982-1-23 1300.00 10</span><br></pre></td></tr></table></figure></li>
<li><p>创建部门表.</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">create table if not exists dept(</span><br><span class="line">deptno int,</span><br><span class="line">dname string,</span><br><span class="line">loc int</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>

<ol>
<li>创建员工表</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">create table if not exists emp(</span><br><span class="line">empno int,</span><br><span class="line">ename string,</span><br><span class="line">job string,</span><br><span class="line">mgr int,</span><br><span class="line">hiredate string, </span><br><span class="line">sal double, </span><br><span class="line">comm double,</span><br><span class="line">deptno int)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure>

<ol>
<li>导入数据</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &#x27;/opt/module/datas/dept.txt&#x27; into table</span><br><span class="line">dept;</span><br><span class="line">load data local inpath &#x27;/opt/module/datas/emp.txt&#x27; into table emp;</span><br></pre></td></tr></table></figure></li>
<li><p>全表查询</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp;</span><br><span class="line">hive (default)&gt; select empno,ename,job,mgr,hiredate,sal,comm,deptno from </span><br><span class="line">emp ;</span><br></pre></td></tr></table></figure></li>
<li><p>选择特定列查询</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select empno, ename from emp;</span><br></pre></td></tr></table></figure>

<ol>
<li><p>SQL 语言大小写不敏感。</p>
</li>
<li><p>SQL 可以写在一行或者多行</p>
</li>
<li><p>关键字不能被缩写也不能分行</p>
</li>
<li><p>各子句一般要分行写。</p>
</li>
<li><p>使用缩进提高语句的可读性。</p>
</li>
</ol>
</li>
</ol>
<h3 id="列别名"><a href="#列别名" class="headerlink" title="列别名"></a>列别名</h3><ol>
<li><p>重命名一个列</p>
</li>
<li><p>便于计算</p>
</li>
<li><p>紧跟列名，也可以在列名和别名之间加入关键字‘AS’ </p>
</li>
<li><p>案例实操</p>
<p>查询名称和部门</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select ename AS name, deptno dn from emp;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="算术运算符"><a href="#算术运算符" class="headerlink" title="算术运算符"></a>算术运算符</h3><table>
<thead>
<tr>
<th>运算符</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>A+B</td>
<td>A 和 B 相加</td>
</tr>
<tr>
<td>A-B</td>
<td>A 减去 B</td>
</tr>
<tr>
<td>A*B</td>
<td>A 和 B 相乘</td>
</tr>
<tr>
<td>A/B</td>
<td>A 除以 B</td>
</tr>
<tr>
<td>A%B</td>
<td>A 对 B 取余</td>
</tr>
<tr>
<td>A&amp;B</td>
<td>A 和 B 按位取与</td>
</tr>
<tr>
<td>A</td>
<td>B</td>
</tr>
<tr>
<td>A^B</td>
<td>A 和 B 按位取异或</td>
</tr>
<tr>
<td>~A</td>
<td>A 按位取反</td>
</tr>
</tbody></table>
<p>案例实操：查询出所有员工的薪水后加 1 显示。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select sal +1 from emp;</span><br></pre></td></tr></table></figure>

<h3 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h3><ol>
<li><p>求总行数（count）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select count(*) cnt from emp;</span><br></pre></td></tr></table></figure></li>
<li><p>求工资的最大值（max）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select max(sal) max_sal from emp;</span><br></pre></td></tr></table></figure></li>
<li><p>求工资的最小值（min）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select min(sal) min_sal from emp;</span><br></pre></td></tr></table></figure></li>
<li><p>求工资的总和（sum）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select sum(sal) sum_sal from emp;</span><br></pre></td></tr></table></figure></li>
<li><p>求工资的平均值（avg）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select avg(sal) avg_sal from emp;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="Limit-语句"><a href="#Limit-语句" class="headerlink" title="Limit 语句"></a>Limit 语句</h3><p>典型的查询会返回多行数据。LIMIT 子句用于限制返回的行数。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp limit 5;</span><br><span class="line">hive (default)&gt; select * from emp limit 2;</span><br></pre></td></tr></table></figure>

<h3 id="Where-语句"><a href="#Where-语句" class="headerlink" title="Where 语句"></a>Where 语句</h3><ol>
<li><p>使用 WHERE 子句，将不满足条件的行过滤掉</p>
</li>
<li><p>WHERE 子句紧随 FROM 子句</p>
</li>
<li><p>案例实操</p>
<p>查询出薪水大于 1000 的所有员工</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp where sal &gt;1000;</span><br></pre></td></tr></table></figure>

<p>注意：where 子句中不能使用字段别名。</p>
</li>
</ol>
<h3 id="比较运算符（Between-In-Is-Null）"><a href="#比较运算符（Between-In-Is-Null）" class="headerlink" title="比较运算符（Between/In/ Is Null）"></a>比较运算符（Between/In/ Is Null）</h3><ol>
<li><p>下面表中描述了谓词操作符，这些操作符同样可以用于 JOIN…ON 和 HAVING 语句中。</p>
<table>
<thead>
<tr>
<th>操作符</th>
<th>支持的数据类型</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>A=B</td>
<td>基本数据类型</td>
<td>如果 A 等于 B 则返回 TRUE，反之返回 FALSE</td>
</tr>
<tr>
<td>A&lt;=&gt;B</td>
<td>基本数据类型</td>
<td>如果 A 和 B 都为 NULL，则返回 TRUE，如果一边为 NULL，返回 False</td>
</tr>
<tr>
<td>A&lt;&gt;B, A!=B</td>
<td>基本数据类型</td>
<td>A 或者 B 为 NULL 则返回 NULL；如果 A 不等于 B，则返回TRUE，反之返回 FALSE</td>
</tr>
<tr>
<td>A&lt;B</td>
<td>基本数据类型</td>
<td>A 或者 B 为 NULL，则返回 NULL；如果 A 小于 B，则返回TRUE，反之返回 FALSE</td>
</tr>
<tr>
<td>A&lt;=B</td>
<td>基本数据类型</td>
<td>A 或者 B 为 NULL，则返回 NULL；如果 A 小于等于 B，则返回 TRUE，反之返回 FALSE</td>
</tr>
<tr>
<td>A&gt;B</td>
<td>基本数据类型</td>
<td>A 或者 B 为 NULL，则返回 NULL；如果 A 大于 B，则返回TRUE，反之返回 FALSE</td>
</tr>
<tr>
<td>A&gt;=B</td>
<td>基本数据类型</td>
<td>A 或者 B 为 NULL，则返回 NULL；如果 A 大于等于 B，则返回 TRUE，反之返回 FALSE</td>
</tr>
<tr>
<td>A [NOT] BETWEEN B AND C</td>
<td>基本数据类型</td>
<td>如果 A，B 或者 C 任一为 NULL，则结果为 NULL。如果 A 的值大于等于 B 而且小于或等于 C，则结果为 TRUE，反之为 FALSE。如果使用 NOT 关键字则可达到相反的效果。</td>
</tr>
<tr>
<td>A IS NULL</td>
<td>所有数据类型</td>
<td>如果 A 等于 NULL，则返回 TRUE，反之返回 FALSE</td>
</tr>
<tr>
<td>A IS NOT NULL</td>
<td>所有数据类型</td>
<td>如果 A 不等于 NULL，则返回 TRUE，反之返回 FALSEIN(数值 1, 数值 2) 所有数据类型 使用 IN 运算显示列表中的值</td>
</tr>
<tr>
<td>A [NOT] LIKE B</td>
<td>STRING 类型</td>
<td>B 是一个 SQL 下的简单正则表达式，也叫通配符模式，如 果 A 与其匹配的话，则返回 TRUE；反之返回 FALSE。B 的表达式说明如下：‘x%’表示 A 必须以字母‘x’开头，‘%x’表示 A必须以字母’x’结尾，而‘%x%’表示 A 包含有字母’x’,可以位于开头，结尾或者字符串中间。如果使用 NOT 关键字则可达到相反的效果。</td>
</tr>
<tr>
<td>A RLIKE B, A REGEXP B</td>
<td>STRING 类型</td>
<td>B 是基于 java 的正则表达式，如果 A 与其匹配，则返回TRUE；反之返回 FALSE。匹配使用的是 JDK 中的正则表达式接口实现的，因为正则也依据其中的规则。例如，正则表达式必须和整个字符串 A 相匹配，而不是只需与其字符串匹配。</td>
</tr>
</tbody></table>
</li>
<li><p>案例实操</p>
<ol>
<li><p>查询出薪水等于 5000 的所有员工</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp where sal =5000;</span><br></pre></td></tr></table></figure></li>
<li><p>查询工资在 500 到 1000 的员工信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp where sal between 500 and 1000;</span><br></pre></td></tr></table></figure></li>
<li><p>查询 comm 为空的所有员工信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp where comm is null;</span><br></pre></td></tr></table></figure></li>
<li><p>查询工资是 1500 或 5000 的员工信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp where sal IN (1500, 5000);</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h3 id="Like-和-RLike"><a href="#Like-和-RLike" class="headerlink" title="Like 和 RLike"></a>Like 和 RLike</h3><ol>
<li><p>使用 LIKE 运算选择类似的值</p>
</li>
<li><p>选择条件可以包含字符或数字:</p>
<p>% 代表零个或多个字符(任意个字符)。</p>
<p>_ 代表一个字符。</p>
</li>
<li><p>RLIKE 子句</p>
<p>RLIKE 子句是 Hive 中这个功能的一个扩展，其可以通过 Java 的正则表达式这个更强大的语言来指定匹配条件。</p>
</li>
<li><p>案例实操</p>
<ol>
<li><p>查找名字以 A 开头的员工信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp where ename LIKE &#x27;A%&#x27;;</span><br></pre></td></tr></table></figure></li>
<li><p>查找名字中第二个字母为 A 的员工信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp where ename LIKE &#x27;_A%&#x27;;</span><br></pre></td></tr></table></figure></li>
<li><p>查找名字中带有 A 的员工信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp where ename RLIKE &#x27;[A]&#x27;;</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h3 id="逻辑运算符（And-Or-Not）"><a href="#逻辑运算符（And-Or-Not）" class="headerlink" title="逻辑运算符（And/Or/Not）"></a>逻辑运算符（And/Or/Not）</h3><table>
<thead>
<tr>
<th>操作符</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>AND</td>
<td>逻辑并</td>
</tr>
<tr>
<td>OR</td>
<td>逻辑或</td>
</tr>
<tr>
<td>NOT</td>
<td>逻辑否</td>
</tr>
</tbody></table>
<ol>
<li><p>案例实操</p>
<ol>
<li><p>查询薪水大于 1000，部门是 30</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp where sal&gt;1000 and deptno=30;</span><br></pre></td></tr></table></figure></li>
<li><p>查询薪水大于 1000，或者部门是 30</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp where sal&gt;1000 or deptno=30;</span><br></pre></td></tr></table></figure></li>
<li><p>查询除了 20 部门和 30 部门以外的员工信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp where deptno not IN(30, 20);</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h2 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h2><h3 id="Group-By-语句"><a href="#Group-By-语句" class="headerlink" title="Group By 语句"></a>Group By 语句</h3><p>GROUP BY 语句通常会和聚合函数一起使用，按照一个或者多个列队结果进行分组，然后对每个组执行聚合操作。</p>
<p>案例实操：</p>
<ol>
<li><p>计算 emp 表每个部门的平均工资</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select t.deptno, avg(t.sal) avg_sal from emp t group by </span><br><span class="line">t.deptno;</span><br></pre></td></tr></table></figure></li>
<li><p>计算 emp 每个部门中每个岗位的最高薪水</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select t.deptno, t.job, max(t.sal) max_sal from emp t </span><br><span class="line">group by</span><br><span class="line">t.deptno, t.job;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="Having-语句"><a href="#Having-语句" class="headerlink" title="Having 语句"></a>Having 语句</h3><ol>
<li><p>having 与 where 不同点</p>
<ol>
<li>where 后面不能写分组函数，而 having 后面可以使用分组函数。</li>
<li>having 只用于 group by 分组统计语句。</li>
</ol>
</li>
<li><p>案例实操</p>
<ol>
<li>求每个部门的平均薪水大于 2000 的部门</li>
</ol>
<p>求每个部门的平均工资</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select deptno, avg(sal) from emp group by deptno;</span><br></pre></td></tr></table></figure>

<p>求每个部门的平均薪水大于 2000 的部门</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select deptno, avg(sal) avg_sal from emp group by deptno </span><br><span class="line">having avg_sal &gt; 2000;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="Join-语句"><a href="#Join-语句" class="headerlink" title="Join 语句"></a>Join 语句</h2><h3 id="等值-Join"><a href="#等值-Join" class="headerlink" title="等值 Join"></a>等值 Join</h3><p>Hive 支持通常的 SQL JOIN 语句。</p>
<h4 id="案例实操"><a href="#案例实操" class="headerlink" title="案例实操"></a>案例实操</h4><ol>
<li><p>根据员工表和部门表中的部门编号相等，查询员工编号、员工名称和部门名称；</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select e.empno, e.ename, d.deptno, d.dname from emp e join dept d on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="表的别名"><a href="#表的别名" class="headerlink" title="表的别名"></a>表的别名</h3><ol>
<li><p>好处</p>
<ol>
<li>使用别名可以简化查询</li>
<li>使用表名前缀可以提高执行效率。</li>
</ol>
</li>
<li><p>案例实操</p>
<p>合并员工表和部门表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select e.empno, e.ename, d.deptno from emp e join dept d </span><br><span class="line">on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="内连接"><a href="#内连接" class="headerlink" title="内连接"></a>内连接</h3><p>内连接：只有进行连接的两个表中都存在与连接条件相匹配的数据才会被保留下来。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select e.empno, e.ename, d.deptno from emp e join dept d </span><br><span class="line">on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>

<h3 id="左外连接"><a href="#左外连接" class="headerlink" title="左外连接"></a>左外连接</h3><p>左外连接：JOIN 操作符左边表中符合 WHERE 子句的所有记录将会被返回。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select e.empno, e.ename, d.deptno from emp e left join </span><br><span class="line">dept d on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>

<h3 id="右外连接"><a href="#右外连接" class="headerlink" title="右外连接"></a>右外连接</h3><p>右外连接：JOIN 操作符右边表中符合 WHERE 子句的所有记录将会被返回。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select e.empno, e.ename, d.deptno from emp e right join </span><br><span class="line">dept d on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>

<h3 id="满外连接"><a href="#满外连接" class="headerlink" title="满外连接"></a>满外连接</h3><p>满外连接：将会返回所有表中符合 WHERE 语句条件的所有记录。如果任一表的指定字段没有符合条件的值的话，那么就使用 NULL 值替代。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select e.empno, e.ename, d.deptno from emp e full join </span><br><span class="line">dept d on e.deptno = d.deptno;</span><br></pre></td></tr></table></figure>

<h3 id="多表连接"><a href="#多表连接" class="headerlink" title="多表连接"></a>多表连接</h3><p>注意：连接 n 个表，至少需要 n-1 个连接条件。例如：连接三个表，至少需要两个连接条件。</p>
<p>数据准备</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1700 Beijing</span><br><span class="line">1800 London</span><br><span class="line">1900 Tokyo</span><br></pre></td></tr></table></figure>

<ol>
<li><p>创建位置表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">create table if not exists location(</span><br><span class="line">loc int,</span><br><span class="line">loc_name string</span><br><span class="line">)</span><br><span class="line">row format delimited fields terminated by &#x27;\t&#x27;;</span><br></pre></td></tr></table></figure></li>
<li><p>导入数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; load data local inpath &#x27;/opt/module/datas/location.txt&#x27; </span><br><span class="line">into table location;</span><br></pre></td></tr></table></figure></li>
<li><p>多表连接查询</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt;SELECT e.ename, d.dname, l.loc_name</span><br><span class="line">FROM emp e </span><br><span class="line">JOIN dept d</span><br><span class="line">ON d.deptno = e.deptno </span><br><span class="line">JOIN location l</span><br><span class="line">ON d.loc = l.loc;</span><br></pre></td></tr></table></figure>

<p>大多数情况下，Hive 会对每对 JOIN 连接对象启动一个 MapReduce 任务。本例中会首先启动一个 MapReduce job 对表 e 和表 d 进行连接操作，然后会再启动一个 MapReduce job 将第一个 MapReduce job 的输出和表 l;进行连接操作。</p>
<p>注意：为什么不是表 d 和表 l 先进行连接操作呢？这是因为 Hive 总是按照从左到右的</p>
<p>顺序执行的。</p>
<p>优化：当对 3 个或者更多表进行 join 连接时，如果每个 on 子句都使用相同的连接键的话，那么只会产生一个 MapReduce job。 </p>
</li>
</ol>
<h3 id="笛卡尔积"><a href="#笛卡尔积" class="headerlink" title="笛卡尔积"></a>笛卡尔积</h3><ol>
<li><p>笛卡尔集会在下面条件下产生</p>
<ol>
<li>省略连接条件</li>
<li>连接条件无效</li>
<li>所有表中的所有行互相连接</li>
</ol>
</li>
<li><p>案例实操</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select empno, dname from emp, dept;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><h3 id="全局排序（Order-By）"><a href="#全局排序（Order-By）" class="headerlink" title="全局排序（Order By）"></a>全局排序（Order By）</h3><p>Order By：全局排序，只有一个 Reducer </p>
<ol>
<li><p>使用 ORDER BY 子句排序</p>
<p>ASC（ascend）: 升序（默认）</p>
<p>DESC（descend）: 降序</p>
</li>
<li><p>ORDER BY 子句在 SELECT 语句的结尾</p>
</li>
<li><p>案例实操</p>
<ol>
<li><p>查询员工信息按工资升序排列</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp order by sal;</span><br></pre></td></tr></table></figure></li>
<li><p>查询员工信息按工资降序排列</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp order by sal desc;</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h3 id="按照别名排序"><a href="#按照别名排序" class="headerlink" title="按照别名排序"></a>按照别名排序</h3><p>按照员工薪水的 2 倍排序</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select ename, sal*2 twosal from emp order by twosal;</span><br></pre></td></tr></table></figure>

<h3 id="多个列排序"><a href="#多个列排序" class="headerlink" title="多个列排序"></a>多个列排序</h3><p>按照部门和工资升序排序</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select ename, deptno, sal from emp order by deptno, sal;</span><br></pre></td></tr></table></figure>

<h3 id="每个-Reduce-内部排序（Sort-By）"><a href="#每个-Reduce-内部排序（Sort-By）" class="headerlink" title="每个 Reduce 内部排序（Sort By）"></a>每个 Reduce 内部排序（Sort By）</h3><p>Sort By：对于大规模的数据集 order by 的效率非常低。在很多情况下，并不需要全局排序，此时可以使用 <strong>sort by</strong>。</p>
<p>Sort by 为每个 reducer 产生一个排序文件。每个 Reducer 内部进行排序，对全局结果集来说不是排序。</p>
<ol>
<li><p>设置 reduce 个数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapreduce.job.reduces=3;</span><br></pre></td></tr></table></figure></li>
<li><p>查看设置 reduce 个数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapreduce.job.reduces;</span><br></pre></td></tr></table></figure></li>
<li><p>根据部门编号降序查看员工信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp sort by deptno desc;</span><br></pre></td></tr></table></figure></li>
<li><p>将查询结果导入到文件中（按照部门编号降序排序）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; insert overwrite local directory </span><br><span class="line">&#x27;/opt/module/data/sortby-result&#x27;</span><br><span class="line">select * from emp sort by deptno desc;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="分区（Distribute-By）"><a href="#分区（Distribute-By）" class="headerlink" title="分区（Distribute By）"></a>分区（Distribute By）</h3><p>Distribute By： </p>
<p>在有些情况下，我们需要控制某个特定行应该到哪个 reducer，通常是为了进行后续的聚集操作。<strong>distribute by</strong> 子句可以做这件事。<strong>distribute by</strong> 类似 MR 中 partition（自定义分区），进行分区，结合 sort by 使用。</p>
<p>对于 distribute by 进行测试，一定要分配多 reduce 进行处理，否则无法看到 distribute by 的效果。</p>
<p>案例实操：</p>
<p>先按照部门编号分区，再按照员工编号降序排序。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set mapreduce.job.reduces=3;</span><br><span class="line">hive (default)&gt; insert overwrite local directory </span><br><span class="line">&#x27;/opt/module/data/distribute-result&#x27; select * from emp distribute by </span><br><span class="line">deptno sort by empno desc;</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<ul>
<li>distribute by 的分区规则是根据分区字段的 hash 码与 reduce 的个数进行模除后，</li>
</ul>
<p>余数相同的分到一个区。 </p>
<ul>
<li>Hive 要求 DISTRIBUTE BY 语句要写在 SORT BY 语句之前。</li>
</ul>
<h3 id="Cluster-By"><a href="#Cluster-By" class="headerlink" title="Cluster By"></a>Cluster By</h3><p>当 distribute by 和 sorts by 字段相同时，可以使用 cluster by 方式。</p>
<p>cluster by 除了具有 distribute by 的功能外还兼具 sort by 的功能。但是排序只能是升序排序，不能指定排序规则为 ASC 或者 DESC。</p>
<p>以下两种写法等价</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; select * from emp cluster by deptno;</span><br><span class="line">hive (default)&gt; select * from emp distribute by deptno sort by deptno;</span><br></pre></td></tr></table></figure>

<p>注意：按照部门编号分区，不一定就是固定死的数值，可以是 20 号和 30 号部门分到一个分区里面去。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://lvxiaoyi.top">lvxiaoyi</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://lvxiaoyi.top/1d83a7d1.html">https://lvxiaoyi.top/1d83a7d1.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://lvxiaoyi.top" target="_blank">吕小医's BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></div><div class="post_share"><div class="social-share" data-image="https://img.lvxiaoyi.top/typora-img/image-20211028174657424.png/lvxiaoyi" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/bc13a2ae.html"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211028174657424.png/lvxiaoyi" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">HBase基础</div></div></a></div><div class="next-post pull-right"><a href="/333cd4b5.html"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/%E5%81%A5%E8%BA%AB.jpg/lvxiaoyi" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">训练计划tips</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/5eb2dc8b.html" title="hadoop基础-3Yarn"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211028174657424.png/lvxiaoyi" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-12</div><div class="title">hadoop基础-3Yarn</div></div></a></div><div><a href="/bc13a2ae.html" title="HBase基础"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211028174657424.png/lvxiaoyi" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-12</div><div class="title">HBase基础</div></div></a></div><div><a href="/9cbb2d93.html" title="hive基础-2"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211028174657424.png/lvxiaoyi" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-12</div><div class="title">hive基础-2</div></div></a></div><div><a href="/6362a21d.html" title="Scala基础-1"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/202111082146936.png/lvxiaoyi" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-12</div><div class="title">Scala基础-1</div></div></a></div><div><a href="/beeb1f38.html" title="Kafka基础"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic2.zhimg.com/v2-9964d2894516902605191817111ec781_r.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-12</div><div class="title">Kafka基础</div></div></a></div><div><a href="/fa6bf3a7.html" title="Scala基础-2"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/202111082146936.png/lvxiaoyi" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-12</div><div class="title">Scala基础-2</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://p0.meituan.net/csc/8a1b1d488e6a8ab5108c9c78f36b3a1776955.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">lvxiaoyi</div><div class="author-info__description">ISFP到ESFJ</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">205</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">27</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">51</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/lvxiaoyi"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">冲鸭！内卷起来了兄弟</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Hive%E5%9F%BA%E7%A1%80-1"><span class="toc-number">1.</span> <span class="toc-text">Hive基础-1</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hive%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">2.</span> <span class="toc-text">Hive基本概念</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFHive"><span class="toc-number">2.1.</span> <span class="toc-text">什么是Hive</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">2.1.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%AC%E8%B4%A8"><span class="toc-number">2.1.2.</span> <span class="toc-text">本质</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive-%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">2.2.</span> <span class="toc-text">Hive 的优缺点</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E7%82%B9"><span class="toc-number">2.2.1.</span> <span class="toc-text">优点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%BA%E7%82%B9"><span class="toc-number">2.2.2.</span> <span class="toc-text">缺点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive-%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86"><span class="toc-number">2.3.</span> <span class="toc-text">Hive 架构原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive-%E5%92%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E6%AF%94%E8%BE%83"><span class="toc-number">2.4.</span> <span class="toc-text">Hive 和数据库比较</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80"><span class="toc-number">2.4.1.</span> <span class="toc-text">查询语言</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%9B%B4%E6%96%B0"><span class="toc-number">2.4.2.</span> <span class="toc-text">数据更新</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%A7%E8%A1%8C%E5%BB%B6%E8%BF%9F"><span class="toc-number">2.4.3.</span> <span class="toc-text">执行延迟</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%A7%84%E6%A8%A1"><span class="toc-number">2.4.4.</span> <span class="toc-text">数据规模</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hive-%E5%AE%89%E8%A3%85"><span class="toc-number">3.</span> <span class="toc-text">Hive 安装</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive-%E5%AE%89%E8%A3%85%E5%9C%B0%E5%9D%80"><span class="toc-number">3.1.</span> <span class="toc-text">Hive 安装地址</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive-%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2"><span class="toc-number">3.2.</span> <span class="toc-text">Hive 安装部署</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85-Hive"><span class="toc-number">3.2.1.</span> <span class="toc-text">安装 Hive</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E5%B9%B6%E4%BD%BF%E7%94%A8-Hive"><span class="toc-number">3.2.2.</span> <span class="toc-text">启动并使用 Hive</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MySQL-%E5%AE%89%E8%A3%85"><span class="toc-number">3.3.</span> <span class="toc-text">MySQL 安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive-%E5%85%83%E6%95%B0%E6%8D%AE%E9%85%8D%E7%BD%AE%E5%88%B0-MySQL"><span class="toc-number">3.4.</span> <span class="toc-text">Hive 元数据配置到 MySQL</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8B%B7%E8%B4%9D%E9%A9%B1%E5%8A%A8"><span class="toc-number">3.4.1.</span> <span class="toc-text">拷贝驱动</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE-Metastore-%E5%88%B0-MySQL"><span class="toc-number">3.4.2.</span> <span class="toc-text">配置 Metastore 到 MySQL</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%8D%E6%AC%A1%E5%90%AF%E5%8A%A8-Hive"><span class="toc-number">3.4.3.</span> <span class="toc-text">再次启动 Hive</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%85%83%E6%95%B0%E6%8D%AE%E6%9C%8D%E5%8A%A1%E7%9A%84%E6%96%B9%E5%BC%8F%E8%AE%BF%E9%97%AE-Hive"><span class="toc-number">3.5.</span> <span class="toc-text">使用元数据服务的方式访问 Hive</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-JDBC-%E6%96%B9%E5%BC%8F%E8%AE%BF%E9%97%AE-Hive"><span class="toc-number">3.6.</span> <span class="toc-text">使用 JDBC 方式访问 Hive</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive-%E5%B8%B8%E7%94%A8%E4%BA%A4%E4%BA%92%E5%91%BD%E4%BB%A4"><span class="toc-number">3.7.</span> <span class="toc-text">Hive 常用交互命令</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive-%E5%85%B6%E4%BB%96%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C"><span class="toc-number">3.8.</span> <span class="toc-text">Hive 其他命令操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hive-%E5%B8%B8%E8%A7%81%E5%B1%9E%E6%80%A7%E9%85%8D%E7%BD%AE"><span class="toc-number">3.9.</span> <span class="toc-text">Hive 常见属性配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive-%E8%BF%90%E8%A1%8C%E6%97%A5%E5%BF%97%E4%BF%A1%E6%81%AF%E9%85%8D%E7%BD%AE"><span class="toc-number">3.9.1.</span> <span class="toc-text">Hive 运行日志信息配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%89%93%E5%8D%B0-%E5%BD%93%E5%89%8D%E5%BA%93-%E5%92%8C-%E8%A1%A8%E5%A4%B4"><span class="toc-number">3.9.2.</span> <span class="toc-text">打印 当前库 和 表头</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E6%96%B9%E5%BC%8F"><span class="toc-number">3.9.3.</span> <span class="toc-text">参数配置方式</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Hive-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">4.</span> <span class="toc-text">Hive 数据类型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">4.1.</span> <span class="toc-text">基本数据类型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9B%86%E5%90%88%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">4.2.</span> <span class="toc-text">集合数据类型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B1%BB%E5%9E%8B%E8%BD%AC%E5%8C%96"><span class="toc-number">4.3.</span> <span class="toc-text">类型转化</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#DDL-%E6%95%B0%E6%8D%AE%E5%AE%9A%E4%B9%89"><span class="toc-number">5.</span> <span class="toc-text">DDL 数据定义</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">5.1.</span> <span class="toc-text">创建数据库</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9F%A5%E8%AF%A2%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">5.2.</span> <span class="toc-text">查询数据库</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%98%BE%E7%A4%BA%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">5.2.1.</span> <span class="toc-text">显示数据库</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E7%9C%8B%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%A6%E6%83%85"><span class="toc-number">5.2.2.</span> <span class="toc-text">查看数据库详情</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%87%E6%8D%A2%E5%BD%93%E5%89%8D%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">5.2.3.</span> <span class="toc-text">切换当前数据库</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">5.3.</span> <span class="toc-text">修改数据库</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%A0%E9%99%A4%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">5.4.</span> <span class="toc-text">删除数据库</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E8%A1%A8"><span class="toc-number">5.5.</span> <span class="toc-text">创建表</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%A1%E7%90%86%E8%A1%A8"><span class="toc-number">5.5.1.</span> <span class="toc-text">管理表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%96%E9%83%A8%E8%A1%A8"><span class="toc-number">5.5.2.</span> <span class="toc-text">外部表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%A1%E7%90%86%E8%A1%A8%E4%B8%8E%E5%A4%96%E9%83%A8%E8%A1%A8%E7%9A%84%E4%BA%92%E7%9B%B8%E8%BD%AC%E6%8D%A2"><span class="toc-number">5.5.3.</span> <span class="toc-text">管理表与外部表的互相转换</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E8%A1%A8"><span class="toc-number">5.6.</span> <span class="toc-text">修改表</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%87%8D%E5%91%BD%E5%90%8D%E8%A1%A8"><span class="toc-number">5.6.1.</span> <span class="toc-text">重命名表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A2%9E%E5%8A%A0%E3%80%81%E4%BF%AE%E6%94%B9%E5%92%8C%E5%88%A0%E9%99%A4%E8%A1%A8%E5%88%86%E5%8C%BA"><span class="toc-number">5.6.2.</span> <span class="toc-text">增加、修改和删除表分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A2%9E%E5%8A%A0-%E4%BF%AE%E6%94%B9-%E6%9B%BF%E6%8D%A2%E5%88%97%E4%BF%A1%E6%81%AF"><span class="toc-number">5.6.3.</span> <span class="toc-text">增加&#x2F;修改&#x2F;替换列信息</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%AD%E6%B3%95"><span class="toc-number">5.6.3.1.</span> <span class="toc-text">语法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E6%93%8D%E6%A1%88%E4%BE%8B"><span class="toc-number">5.6.3.2.</span> <span class="toc-text">实操案例</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%A0%E9%99%A4%E8%A1%A8"><span class="toc-number">5.7.</span> <span class="toc-text">删除表</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#DML-%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C"><span class="toc-number">6.</span> <span class="toc-text">DML 数据操作</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5"><span class="toc-number">6.1.</span> <span class="toc-text">数据导入</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%91%E8%A1%A8%E4%B8%AD%E8%A3%85%E8%BD%BD%E6%95%B0%E6%8D%AE%EF%BC%88Load%EF%BC%89"><span class="toc-number">6.1.1.</span> <span class="toc-text">向表中装载数据（Load）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%AD%E6%B3%95-1"><span class="toc-number">6.1.1.1.</span> <span class="toc-text">语法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E6%93%8D%E6%A1%88%E4%BE%8B-1"><span class="toc-number">6.1.1.2.</span> <span class="toc-text">实操案例</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%9A%E8%BF%87%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E5%90%91%E8%A1%A8%E4%B8%AD%E6%8F%92%E5%85%A5%E6%95%B0%E6%8D%AE%EF%BC%88Insert%EF%BC%89"><span class="toc-number">6.1.2.</span> <span class="toc-text">通过查询语句向表中插入数据（Insert）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E4%B8%AD%E5%88%9B%E5%BB%BA%E8%A1%A8%E5%B9%B6%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%EF%BC%88As-Select%EF%BC%89"><span class="toc-number">6.1.3.</span> <span class="toc-text">查询语句中创建表并加载数据（As Select）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E8%A1%A8%E6%97%B6%E9%80%9A%E8%BF%87-Location-%E6%8C%87%E5%AE%9A%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E8%B7%AF%E5%BE%84"><span class="toc-number">6.1.4.</span> <span class="toc-text">创建表时通过 Location 指定加载数据路径</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Import-%E6%95%B0%E6%8D%AE%E5%88%B0%E6%8C%87%E5%AE%9A-Hive-%E8%A1%A8%E4%B8%AD"><span class="toc-number">6.1.5.</span> <span class="toc-text">Import 数据到指定 Hive 表中</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%87%BA"><span class="toc-number">6.2.</span> <span class="toc-text">数据导出</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Insert-%E5%AF%BC%E5%87%BA"><span class="toc-number">6.2.1.</span> <span class="toc-text">Insert 导出</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hadoop-%E5%91%BD%E4%BB%A4%E5%AF%BC%E5%87%BA%E5%88%B0%E6%9C%AC%E5%9C%B0"><span class="toc-number">6.2.2.</span> <span class="toc-text">Hadoop 命令导出到本地</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive-Shell-%E5%91%BD%E4%BB%A4%E5%AF%BC%E5%87%BA"><span class="toc-number">6.2.3.</span> <span class="toc-text">Hive Shell 命令导出</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Export-%E5%AF%BC%E5%87%BA%E5%88%B0-HDFS-%E4%B8%8A"><span class="toc-number">6.2.4.</span> <span class="toc-text">Export 导出到 HDFS 上</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sqoop-%E5%AF%BC%E5%87%BA"><span class="toc-number">6.2.5.</span> <span class="toc-text">Sqoop 导出</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B8%85%E9%99%A4%E8%A1%A8%E4%B8%AD%E6%95%B0%E6%8D%AE%EF%BC%88Truncate%EF%BC%89"><span class="toc-number">6.2.6.</span> <span class="toc-text">清除表中数据（Truncate）</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%9F%A5%E8%AF%A2"><span class="toc-number">7.</span> <span class="toc-text">查询</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%9F%A5%E8%AF%A2%EF%BC%88Select%E2%80%A6From%EF%BC%89"><span class="toc-number">7.1.</span> <span class="toc-text">基本查询（Select…From）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E8%A1%A8%E5%92%8C%E7%89%B9%E5%AE%9A%E5%88%97%E6%9F%A5%E8%AF%A2"><span class="toc-number">7.1.1.</span> <span class="toc-text">全表和特定列查询</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%97%E5%88%AB%E5%90%8D"><span class="toc-number">7.1.2.</span> <span class="toc-text">列别名</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%97%E6%9C%AF%E8%BF%90%E7%AE%97%E7%AC%A6"><span class="toc-number">7.1.3.</span> <span class="toc-text">算术运算符</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0"><span class="toc-number">7.1.4.</span> <span class="toc-text">常用函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Limit-%E8%AF%AD%E5%8F%A5"><span class="toc-number">7.1.5.</span> <span class="toc-text">Limit 语句</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Where-%E8%AF%AD%E5%8F%A5"><span class="toc-number">7.1.6.</span> <span class="toc-text">Where 语句</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AF%94%E8%BE%83%E8%BF%90%E7%AE%97%E7%AC%A6%EF%BC%88Between-In-Is-Null%EF%BC%89"><span class="toc-number">7.1.7.</span> <span class="toc-text">比较运算符（Between&#x2F;In&#x2F; Is Null）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Like-%E5%92%8C-RLike"><span class="toc-number">7.1.8.</span> <span class="toc-text">Like 和 RLike</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E8%BF%90%E7%AE%97%E7%AC%A6%EF%BC%88And-Or-Not%EF%BC%89"><span class="toc-number">7.1.9.</span> <span class="toc-text">逻辑运算符（And&#x2F;Or&#x2F;Not）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E7%BB%84"><span class="toc-number">7.2.</span> <span class="toc-text">分组</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Group-By-%E8%AF%AD%E5%8F%A5"><span class="toc-number">7.2.1.</span> <span class="toc-text">Group By 语句</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Having-%E8%AF%AD%E5%8F%A5"><span class="toc-number">7.2.2.</span> <span class="toc-text">Having 语句</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Join-%E8%AF%AD%E5%8F%A5"><span class="toc-number">7.3.</span> <span class="toc-text">Join 语句</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AD%89%E5%80%BC-Join"><span class="toc-number">7.3.1.</span> <span class="toc-text">等值 Join</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%93%8D"><span class="toc-number">7.3.1.1.</span> <span class="toc-text">案例实操</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A1%A8%E7%9A%84%E5%88%AB%E5%90%8D"><span class="toc-number">7.3.2.</span> <span class="toc-text">表的别名</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%85%E8%BF%9E%E6%8E%A5"><span class="toc-number">7.3.3.</span> <span class="toc-text">内连接</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B7%A6%E5%A4%96%E8%BF%9E%E6%8E%A5"><span class="toc-number">7.3.4.</span> <span class="toc-text">左外连接</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%B3%E5%A4%96%E8%BF%9E%E6%8E%A5"><span class="toc-number">7.3.5.</span> <span class="toc-text">右外连接</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%BB%A1%E5%A4%96%E8%BF%9E%E6%8E%A5"><span class="toc-number">7.3.6.</span> <span class="toc-text">满外连接</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E8%A1%A8%E8%BF%9E%E6%8E%A5"><span class="toc-number">7.3.7.</span> <span class="toc-text">多表连接</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AC%9B%E5%8D%A1%E5%B0%94%E7%A7%AF"><span class="toc-number">7.3.8.</span> <span class="toc-text">笛卡尔积</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%92%E5%BA%8F"><span class="toc-number">7.4.</span> <span class="toc-text">排序</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%A8%E5%B1%80%E6%8E%92%E5%BA%8F%EF%BC%88Order-By%EF%BC%89"><span class="toc-number">7.4.1.</span> <span class="toc-text">全局排序（Order By）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%89%E7%85%A7%E5%88%AB%E5%90%8D%E6%8E%92%E5%BA%8F"><span class="toc-number">7.4.2.</span> <span class="toc-text">按照别名排序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E4%B8%AA%E5%88%97%E6%8E%92%E5%BA%8F"><span class="toc-number">7.4.3.</span> <span class="toc-text">多个列排序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AF%8F%E4%B8%AA-Reduce-%E5%86%85%E9%83%A8%E6%8E%92%E5%BA%8F%EF%BC%88Sort-By%EF%BC%89"><span class="toc-number">7.4.4.</span> <span class="toc-text">每个 Reduce 内部排序（Sort By）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%8C%BA%EF%BC%88Distribute-By%EF%BC%89"><span class="toc-number">7.4.5.</span> <span class="toc-text">分区（Distribute By）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Cluster-By"><span class="toc-number">7.4.6.</span> <span class="toc-text">Cluster By</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/560e8e48.html" title="博客美化"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic2.zhimg.com/v2-9964d2894516902605191817111ec781_r.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="博客美化"/></a><div class="content"><a class="title" href="/560e8e48.html" title="博客美化">博客美化</a><time datetime="2023-12-29T14:58:12.257Z" title="发表于 2023-12-29 22:58:12">2023-12-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/7ef7bbd4.html" title="LeetCode 118. 杨辉三角"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/202111011355394.png/lvxiaoyi" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="LeetCode 118. 杨辉三角"/></a><div class="content"><a class="title" href="/7ef7bbd4.html" title="LeetCode 118. 杨辉三角">LeetCode 118. 杨辉三角</a><time datetime="2023-03-19T14:25:59.394Z" title="发表于 2023-03-19 22:25:59">2023-03-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/82c8cab7.html" title="shell基础"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic2.zhimg.com/v2-9964d2894516902605191817111ec781_r.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="shell基础"/></a><div class="content"><a class="title" href="/82c8cab7.html" title="shell基础">shell基础</a><time datetime="2022-10-12T16:07:18.841Z" title="发表于 2022-10-13 00:07:18">2022-10-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/f1601c3e.html" title="单例模式"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/1002892-20180912131026735-781767905.png/lvxiaoyi" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="单例模式"/></a><div class="content"><a class="title" href="/f1601c3e.html" title="单例模式">单例模式</a><time datetime="2022-09-12T07:22:48.777Z" title="发表于 2022-09-12 15:22:48">2022-09-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/b15f0f1b.html" title="设计模式基础-1"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211012093705433.png/lvxiaoyi" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="设计模式基础-1"/></a><div class="content"><a class="title" href="/b15f0f1b.html" title="设计模式基础-1">设计模式基础-1</a><time datetime="2022-09-12T07:22:48.777Z" title="发表于 2022-09-12 15:22:48">2022-09-12</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://img.lvxiaoyi.top/typora-img/image-20211028174657424.png/lvxiaoyi')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By lvxiaoyi</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"></div><canvas id="universe"></canvas><script defer src="/js/lvxiaoyi.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>