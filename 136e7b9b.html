<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>hadoop基础-1 | 吕小医's BLOG</title><meta name="keywords" content="大数据"><meta name="author" content="lvxiaoyi"><meta name="copyright" content="lvxiaoyi"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="hadoop基础-1视频资料和笔记资料来自尚硅谷：https:&#x2F;&#x2F;www.bilibili.com&#x2F;video&#x2F;BV1Qp4y1n7EN?p&#x3D;1 资料：https:&#x2F;&#x2F;pan.baidu.com&#x2F;s&#x2F;1P5JAtWlGDKMAPWmHAAcbyA，提取码：5h60 概述发展是什么 Hadoop是一个由Apache基金会所开发的分布式系统基础架构  主要解决，海量数据的存储和海量数据的分析计算问题。">
<meta property="og:type" content="article">
<meta property="og:title" content="hadoop基础-1">
<meta property="og:url" content="https://lvxiaoyi.top/136e7b9b.html">
<meta property="og:site_name" content="吕小医&#39;s BLOG">
<meta property="og:description" content="hadoop基础-1视频资料和笔记资料来自尚硅谷：https:&#x2F;&#x2F;www.bilibili.com&#x2F;video&#x2F;BV1Qp4y1n7EN?p&#x3D;1 资料：https:&#x2F;&#x2F;pan.baidu.com&#x2F;s&#x2F;1P5JAtWlGDKMAPWmHAAcbyA，提取码：5h60 概述发展是什么 Hadoop是一个由Apache基金会所开发的分布式系统基础架构  主要解决，海量数据的存储和海量数据的分析计算问题。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://img.lvxiaoyi.top/typora-img/image-20211028174657424.png/lvxiaoyi">
<meta property="article:published_time" content="2022-09-12T07:22:48.770Z">
<meta property="article:modified_time" content="2022-09-12T07:22:48.770Z">
<meta property="article:author" content="lvxiaoyi">
<meta property="article:tag" content="大数据">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://img.lvxiaoyi.top/typora-img/image-20211028174657424.png/lvxiaoyi"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://lvxiaoyi.top/136e7b9b"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'hadoop基础-1',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-09-12 15:22:48'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://p0.meituan.net/csc/8a1b1d488e6a8ab5108c9c78f36b3a1776955.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">205</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">27</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">51</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 小医</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://img.lvxiaoyi.top/typora-img/image-20211028174657424.png/lvxiaoyi')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">吕小医's BLOG</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 小医</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">hadoop基础-1</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-09-12T07:22:48.770Z" title="发表于 2022-09-12 15:22:48">2022-09-12</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-09-12T07:22:48.770Z" title="更新于 2022-09-12 15:22:48">2022-09-12</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/">hadoop</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="hadoop基础-1"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="hadoop基础-1"><a href="#hadoop基础-1" class="headerlink" title="hadoop基础-1"></a>hadoop基础-1</h1><p>视频资料和笔记资料来自尚硅谷：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Qp4y1n7EN?p=1">https://www.bilibili.com/video/BV1Qp4y1n7EN?p=1</a></p>
<p>资料：<a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1P5JAtWlGDKMAPWmHAAcbyA%EF%BC%8C%E6%8F%90%E5%8F%96%E7%A0%81%EF%BC%9A5h60">https://pan.baidu.com/s/1P5JAtWlGDKMAPWmHAAcbyA，提取码：5h60</a></p>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="发展"><a href="#发展" class="headerlink" title="发展"></a>发展</h2><h3 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h3><ul>
<li><p>Hadoop是一个由Apache基金会所开发的分布式系统基础架构</p>
</li>
<li><p>主要解决，海量数据的存储和海量数据的分析计算问题。</p>
</li>
<li><p>广义上来说，Hadoop通常是指一个更广泛的概念——Hadoop生态圈。</p>
</li>
</ul>
<h3 id="发展历史"><a href="#发展历史" class="headerlink" title="发展历史"></a>发展历史</h3><ol>
<li>Hadoop创始人DougCutting，为了实现与Google类似的全文搜索功能，他在Lucene框架基础上进行优</li>
</ol>
<p>化升级，查询引擎和索引引擎。</p>
<ol start="2">
<li><p>2001年年底Lucene成为Apache基金会的一个子项目。</p>
</li>
<li><p>对于海量数据的场景，Lucene框架面对与Google同样的困难，存储海量数据困难，检索海量速度慢。</p>
</li>
<li><p>学习和模仿Google解决这些问题的办法：微型版Nutch。</p>
</li>
<li><p>可以说Google是Hadoop的思想之源（Google在大数据方面的三篇论文）</p>
</li>
<li><p>2003-2004年，Google公开了部分GFS和MapReduce思想的细节，以此为基础Doug Cutting等人用了2年业余时间实现了DFS和MapReduce机制，使Nutch性能飙升。</p>
</li>
<li><p>2005年Hadoop作为Lucene的子项目Nutch的一部分正式引入Apache基金会。</p>
</li>
<li><p>2006年3月份，Map-Reduce和NutchDistributedFileSystem（NDFS）分别被纳入到Hadoop项目中，Hadoop就此正式诞生，标志着大数据时代来临。</p>
</li>
<li><p>名字来源于DougCutting儿子的玩具大象</p>
</li>
</ol>
<h3 id="三大版本"><a href="#三大版本" class="headerlink" title="三大版本"></a>三大版本</h3><p>Hadoop三大发行版本：Apache、Cloudera、Hortonworks。</p>
<p>Apache版本最原始（最基础）的版本，对于入门学习最好。2006 </p>
<p>Cloudera内部集成了很多大数据框架，对应产品CDH。2008</p>
<p>Hortonworks文档较好，对应产品HDP。2011</p>
<p>Hortonworks现在已经被Cloudera公司收购，推出新的品牌CDP。</p>
<h3 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h3><ul>
<li>高可靠性：Hadoop底层维护多个数据副本，所以即使Hadoop某个计算元素或存储出现故障，也不会导致数据的丢失。</li>
<li>高扩展性：在集群间分配任务数据，可方便的扩展数以千计的节点。</li>
<li>高效性：在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度。</li>
<li>高容错性：能够自动将失败的任务重新分配。</li>
</ul>
<h2 id="hadoop组成"><a href="#hadoop组成" class="headerlink" title="hadoop组成"></a>hadoop组成</h2><p>在Hadoop1.x时代，Hadoop中的MapReduce同时处理业务逻辑运算和资源的调度，耦合性较大。</p>
<p>在Hadoop2.x时代，增加了Yarn。Yarn只负责资源的调度MapReduce只负责运算。</p>
<p>Hadoop3.x在组成上没有变化。</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/202111010945468.png/lvxiaoyi" alt="image-20211028173212945" style="zoom:67%;" />

<h3 id="HDFS架构概述"><a href="#HDFS架构概述" class="headerlink" title="HDFS架构概述"></a>HDFS架构概述</h3><p>Hadoop Distributed File System，简称 HDFS，是一个分布式文件系统。</p>
<h4 id="组成"><a href="#组成" class="headerlink" title="组成"></a>组成</h4><ol>
<li><p>NameNode（nn）：存储文件的<strong>元数据</strong>，如<strong>文件名，文件目录结构，文件属性</strong>（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的DataNode等。 </p>
</li>
<li><p>DataNode(dn)：在本地文件系统<strong>存储文件块数据</strong>，以及<strong>块数据的校验和</strong>。</p>
</li>
<li><p>Secondary NameNode(2nn)：<strong>每隔一段时间对<strong><strong>NameNode</strong></strong>元数据备份</strong>。 </p>
</li>
</ol>
<h3 id="YARN概述"><a href="#YARN概述" class="headerlink" title="YARN概述"></a>YARN概述</h3><p>Yet Another Resource Negotiator 简称 YARN ，另一种资源协调者，是 Hadoop 的资源管理器。</p>
<ul>
<li><p>ResourceManager（RM）：整个集群资源（内存、CPU等）的老大</p>
</li>
<li><p>NodeManager（NM）：单个节点服务器资源老大</p>
</li>
<li><p>ApplicationMaster（AM）：单个任务运行的老大</p>
</li>
<li><p>Container：容器，相当一台独立的服务器，里面封装了任务运行所需要的资源，如内存、CPU、磁盘、网络等。 </p>
</li>
</ul>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211028174006739.png/lvxiaoyi" alt="image-20211028174006739" style="zoom:67%;" />



<p>说明1：客户端可以有多个</p>
<p>说明2：集群上可以运行多个ApplicationMaster</p>
<p>说明3：每个NodeManager上可以有多个Container</p>
<h3 id="MapReduce-架构概述"><a href="#MapReduce-架构概述" class="headerlink" title="MapReduce 架构概述"></a><strong>MapReduce</strong> <strong>架构概述</strong></h3><p>MapReduce 将计算过程分为两个阶段：Map 和 Reduce</p>
<p>Map 阶段并行处理输入数据，Reduce 阶段对 Map 结果进行汇总</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211028174112742.png/lvxiaoyi" alt="image-20211028174112742" style="zoom:67%;" />

<h3 id="HDFS、YARN、MapReduce-三者关系"><a href="#HDFS、YARN、MapReduce-三者关系" class="headerlink" title="HDFS、YARN、MapReduce 三者关系"></a><strong>HDFS</strong>、YARN、MapReduce <strong>三者关系</strong></h3><p>HDFS存储文件，然后MapReduce去统计计算文件，但是MapReduce不知道去哪一个节点上寻找文件，那么yarn就是这个资源管理者，去分发任务。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211028174440867.png/lvxiaoyi" alt="image-20211028174440867"></p>
<h2 id="大数据技术生态体系"><a href="#大数据技术生态体系" class="headerlink" title="大数据技术生态体系"></a>大数据技术生态体系</h2><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211028174657424.png/lvxiaoyi" alt="image-20211028174657424" style="zoom:67%;" />

<p>图中涉及的技术名词解释如下：</p>
<ul>
<li><p>Sqoop：Sqoop 是一款开源的工具，主要用于在 Hadoop、Hive 与传统的数据库（MySQL）间进行数据的传递，可以将一个关系型数据库（例如 ：MySQL，Oracle 等）中的数据导进到 Hadoop 的 HDFS 中，也可以将 HDFS 的数据导进到关系型数据库中。</p>
</li>
<li><p>Flume：Flume 是一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume 支持在日志系统中定制各类数据发送方，用于收集数据；</p>
</li>
<li><p>Kafka：Kafka 是一种高吞吐量的分布式发布订阅消息系统；</p>
</li>
<li><p>Spark：Spark 是当前最流行的开源大数据内存计算框架。可以基于 Hadoop 上存储的大数据进行计算。</p>
</li>
<li><p>Flink：Flink 是当前最流行的开源大数据内存计算框架。用于实时计算的场景较多。</p>
</li>
<li><p>Oozie：Oozie 是一个管理 Hadoop 作业（job）的工作流程调度管理系统。</p>
</li>
<li><p>Hbase：HBase 是一个分布式的、面向列的开源数据库。HBase 不同于一般的关系数据库，它是一个适合于非结构化数据存储的数据库。</p>
</li>
<li><p>Hive：Hive 是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的 SQL 查询功能，可以将 SQL 语句转换为 MapReduce 任务进行运行。其优点是学习成本低，可以通过类 SQL 语句快速实现简单的 MapReduce 统计，不必开发专门的 MapReduce 应用，十分适合数据仓库的统计分析。</p>
</li>
<li><p>ZooKeeper：它是一个针对大型分布式系统的可靠协调系统，提供的功能包括：配置维护、名字服务、分布式同步、组服务等</p>
</li>
</ul>
<h2 id="系统框架图"><a href="#系统框架图" class="headerlink" title="系统框架图"></a>系统框架图</h2><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211028175014282.png/lvxiaoyi" alt="image-20211028175014282"></p>
<h1 id="hadoop环境搭建"><a href="#hadoop环境搭建" class="headerlink" title="hadoop环境搭建"></a>hadoop环境搭建</h1><h2 id="模板虚拟机环境准备"><a href="#模板虚拟机环境准备" class="headerlink" title="模板虚拟机环境准备"></a>模板虚拟机环境准备</h2><h3 id="安装模板虚拟机"><a href="#安装模板虚拟机" class="headerlink" title="安装模板虚拟机"></a>安装模板虚拟机</h3><p><strong>IP <strong>地址</strong> 192.168.10.100</strong>、主机名称** hadoop100<strong>、内存</strong> 4G<strong>、</strong>硬盘 50G</p>
<h4 id="hadoop100-虚拟机配置"><a href="#hadoop100-虚拟机配置" class="headerlink" title="hadoop100 虚拟机配置"></a><strong>hadoop100</strong> <strong>虚拟机配置</strong></h4><p>hadoop100： <strong>虚拟机配置要求如下（本文</strong> <strong>Linux</strong> <strong>系统全部以</strong> <strong>CentOS-7.5-x86-1804</strong> <strong>为例）</strong> </p>
<ol>
<li>使用 yum 安装需要虚拟机可以正常上网，yum 安装前可以先测试下虚拟机联网情况</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]<span class="comment"># ping www.baidu.com</span></span><br><span class="line">PING www.baidu.com (14.215.177.39) 56(84) bytes of data.</span><br><span class="line">64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=1 </span><br><span class="line">ttl=128 time=8.60 ms</span><br><span class="line">64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=2 </span><br><span class="line">ttl=128 time=7.72 ms</span><br></pre></td></tr></table></figure>

<ol start="2">
<li> 安装 epel-release</li>
</ol>
<p>注：Extra Packages for Enterprise Linux 是为“红帽系”的操作系统提供额外的软件包，适用于 RHEL、CentOS 和 Scientific Linux。相当于是一个软件仓库，大多数 rpm 包在官方repository 中是找不到的）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# yum install -y epel-release</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><p>注意：如果 Linux 安装的是最小系统版，还需要安装如下工具；如果安装的是 Linux桌面标准版，不需要执行如下操作</p>
<p>net-tool：工具包集合，包含 ifconfig 等命令</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# yum install -y net-tools</span><br></pre></td></tr></table></figure>

<p>​    vim：编辑器</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# yum install -y vim</span><br></pre></td></tr></table></figure>

<h4 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a><strong>关闭防火墙</strong></h4><p><strong>关闭防火墙，关闭防火墙开机自启</strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]<span class="comment"># systemctl stop firewalld</span></span><br><span class="line"></span><br><span class="line">[root@hadoop100 ~]<span class="comment"># systemctl disable firewalld.service</span></span><br></pre></td></tr></table></figure>

<p>注意：在企业开发时，通常单个服务器的防火墙时关闭的。公司整体对外会设置非常安全的防火墙</p>
<h4 id="创建-lvxiaoyi-用户"><a href="#创建-lvxiaoyi-用户" class="headerlink" title="创建 lvxiaoyi 用户"></a>创建 <strong>lvxiaoyi</strong> <strong>用户</strong></h4><p><strong>创建</strong> lvxiaoyi用户，并修改 <strong>lvxiaoyi</strong> <strong>用户的密码</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# useradd lvxiaoyi</span><br><span class="line">[root@hadoop100 ~]# passwd lvxiaoyi</span><br></pre></td></tr></table></figure>

<p>注意：这一步的密码需要较为复杂的密码，否则不能通过</p>
<h4 id="设置权限"><a href="#设置权限" class="headerlink" title="设置权限"></a>设置权限</h4><p><strong>配置</strong> <strong>lvxiaoyi</strong> <strong>用户具有</strong> <strong>root</strong> <strong>权限，方便后期加</strong> <strong>sudo</strong> <strong>执行</strong> <strong>root</strong> <strong>权限的命令</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# vim /etc/sudoers</span><br></pre></td></tr></table></figure>

<p>修改/etc/sudoers 文件，在%wheel 这行下面添加一行，如下所示：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## Allow root to run any commands anywhere</span></span><br><span class="line">root ALL=(ALL) ALL</span><br><span class="line"><span class="comment">## Allows people in group wheel to run all commands</span></span><br><span class="line">%wheel ALL=(ALL) ALL</span><br><span class="line">lvxiaoyi ALL=(ALL) NOPASSWD:ALL</span><br></pre></td></tr></table></figure>

<p>注意：lvxiaoyi 这一行不要直接放到 root 行下面，因为所有用户都属于 wheel 组，你先配置了 lvxiaoyi 具有免密功能，但是程序执行到%wheel 行时，该功能又被覆盖回需要密码。所以 lvxiaoyi 要放到%wheel 这行下面。</p>
<h4 id="创建软件存放位置"><a href="#创建软件存放位置" class="headerlink" title="创建软件存放位置"></a>创建软件存放位置</h4><p>在/opt 目录下创建文件夹，并修改所属主和所属组</p>
<ul>
<li>在/opt 目录下创建 module、software 文件夹</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]<span class="comment"># mkdir /opt/module</span></span><br><span class="line">[root@hadoop100 ~]<span class="comment"># mkdir /opt/software</span></span><br></pre></td></tr></table></figure>

<ul>
<li>修改 module、software 文件夹的所有者和所属组均为 lvxiaoyi 用户</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]<span class="comment"># chown lvxiaoyi:lvxiaoyi /opt/module </span></span><br><span class="line">[root@hadoop100 ~]<span class="comment"># chown lvxiaoyi:lvxiaoyi /opt/software</span></span><br></pre></td></tr></table></figure>

<ul>
<li>查看 module、software 文件夹的所有者和所属组</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop103 ~]$ <span class="built_in">cd</span> /opt/</span><br><span class="line">[lvxiaoyi@hadoop103 opt]$ ll</span><br><span class="line">总用量 0</span><br><span class="line">drwxr-xr-x. 4 lvxiaoyi lvxiaoyi 46 10月 28 16:40 module</span><br><span class="line">drwxr-xr-x. 2 lvxiaoyi lvxiaoyi  6 10月 28 14:41 software</span><br></pre></td></tr></table></figure>

<h4 id="卸载自带jdk"><a href="#卸载自带jdk" class="headerlink" title="卸载自带jdk"></a>卸载自带jdk</h4><p>注意：如果你的虚拟机是最小化安装不需要执行这一步。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps</span><br></pre></td></tr></table></figure>

<ul>
<li>rpm -qa：查询所安装的所有 rpm 软件包</li>
<li>grep -i：忽略大小写</li>
<li>xargs -n1：表示每次只传递一个参数</li>
<li>rpm -e –nodeps：强制卸载软件</li>
</ul>
<h4 id="重启"><a href="#重启" class="headerlink" title="重启"></a>重启</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# reboot</span><br></pre></td></tr></table></figure>

<h3 id="克隆虚拟机"><a href="#克隆虚拟机" class="headerlink" title="克隆虚拟机"></a>克隆虚拟机</h3><h4 id="克隆"><a href="#克隆" class="headerlink" title="克隆"></a>克隆</h4><p>利用模板机 hadoop100，克隆三台虚拟机：hadoop102 hadoop103 hadoop104</p>
<p>注意：克隆时，要先关闭 hadoop100</p>
<h4 id="修改ip"><a href="#修改ip" class="headerlink" title="修改ip"></a>修改ip</h4><p><strong>修改克隆机</strong> <strong>IP</strong>，以下<strong>hadoop102</strong> <strong>举例说明</strong></p>
<ul>
<li><p>修改克隆虚拟机的静态 IP</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]# vim /etc/sysconfig/network-scripts/ifcfg-ens33</span><br></pre></td></tr></table></figure>

<p>改成：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">DEVICE=ens33</span><br><span class="line">TYPE=Ethernet</span><br><span class="line">ONBOOT=yes</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">NAME=<span class="string">&quot;ens33&quot;</span></span><br><span class="line">IPADDR=192.168.10.102</span><br><span class="line">PREFIX=24</span><br><span class="line">GATEWAY=192.168.10.2</span><br><span class="line">DNS1=192.168.10.2</span><br></pre></td></tr></table></figure></li>
<li><p>查看 Linux 虚拟机的虚拟网络编辑器，编辑-&gt;虚拟网络编辑器-&gt;VMnet8</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211028181219597.png/lvxiaoyi" alt="image-20211028181219597" style="zoom:67%;" />

<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211028181242268.png/lvxiaoyi" alt="image-20211028181242268" style="zoom:67%;" /></li>
<li><p>查看 Windows 系统适配器 VMware Network Adapter VMnet8 的 IP 地址</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211028181317441.png/lvxiaoyi" alt="image-20211028181317441"></p>
</li>
<li><p>保证 Linux 系统 ifcfg-ens33 文件中 IP 地址、虚拟网络编辑器地址和 Windows 系 统 VM8 网络 IP 地址相同。</p>
</li>
</ul>
<h4 id="修改克隆主机名"><a href="#修改克隆主机名" class="headerlink" title="修改克隆主机名"></a>修改克隆主机名</h4><p>修改克隆机主机名，以下以 hadoop102 举例说明</p>
<ul>
<li><p>修改主机名称</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]<span class="comment"># vim /etc/hostname</span></span><br><span class="line">hadoop102</span><br></pre></td></tr></table></figure></li>
<li><p>配置 Linux 克隆机主机名称映射 hosts 文件，打开/etc/hosts</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]<span class="comment"># vim /etc/hosts</span></span><br></pre></td></tr></table></figure>

<p>添加如下内容：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">192.168.10.100 hadoop100</span><br><span class="line">192.168.10.101 hadoop101</span><br><span class="line">192.168.10.102 hadoop102</span><br><span class="line">192.168.10.103 hadoop103</span><br><span class="line">192.168.10.104 hadoop104</span><br><span class="line">192.168.10.105 hadoop105</span><br><span class="line">192.168.10.106 hadoop106</span><br><span class="line">192.168.10.107 hadoop107</span><br><span class="line">192.168.10.108 hadoop108</span><br></pre></td></tr></table></figure></li>
<li><p><strong>重启克隆机</strong> <strong>hadoop102</strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@hadoop100 ~]<span class="comment"># reboot</span></span><br></pre></td></tr></table></figure></li>
<li><p>修改 windows的主机映射文件（host文件）</p>
<ul>
<li><p>如果操作系统是 window7，可以直接修改</p>
<ul>
<li>进入 C:\Windows\System32\drivers\etc 路径</li>
<li>打开 hosts 文件并添加如下内容，然后保存</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">192.168.10.100 hadoop100</span><br><span class="line">192.168.10.101 hadoop101</span><br><span class="line">192.168.10.102 hadoop102</span><br><span class="line">192.168.10.103 hadoop103</span><br><span class="line">192.168.10.104 hadoop104</span><br><span class="line">192.168.10.105 hadoop105</span><br><span class="line">192.168.10.106 hadoop106</span><br><span class="line">192.168.10.107 hadoop107</span><br><span class="line">192.168.10.108 hadoop108</span><br></pre></td></tr></table></figure></li>
<li><p>如果操作系统是 window10，先拷贝出来，修改保存以后，再覆盖即可（或者notepadd++直接可以操作）</p>
<ul>
<li><p>进入 C:\Windows\System32\drivers\etc 路径</p>
</li>
<li><p>拷贝 hosts 文件到桌面</p>
</li>
<li><p>打开桌面 hosts 文件并添加如下内容</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">192.168.10.100 hadoop100</span><br><span class="line">192.168.10.101 hadoop101</span><br><span class="line">192.168.10.102 hadoop102</span><br><span class="line">192.168.10.103 hadoop103</span><br><span class="line">192.168.10.104 hadoop104</span><br><span class="line">192.168.10.105 hadoop105</span><br><span class="line">192.168.10.106 hadoop106</span><br><span class="line">192.168.10.107 hadoop107</span><br><span class="line">192.168.10.108 hadoop108</span><br></pre></td></tr></table></figure></li>
<li><p>将桌面 hosts 文件覆盖 C:\Windows\System32\drivers\etc 路径 hosts 文件</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="安装-JDK"><a href="#安装-JDK" class="headerlink" title="安装 JDK"></a><strong>安装</strong> <strong>JDK</strong></h3><h4 id="卸载现有-JDK"><a href="#卸载现有-JDK" class="headerlink" title="卸载现有 JDK"></a><strong>卸载现有</strong> <strong>JDK</strong></h4><p>注意：安装 JDK 前，一定确保提前删除了虚拟机自带的 JDK。详细步骤见问文档 3.1 节中卸载 JDK 步骤。</p>
<h4 id="传输jdk文件"><a href="#传输jdk文件" class="headerlink" title="传输jdk文件"></a>传输jdk文件</h4><p>用 XShell 传输工具将 JDK 导入到 opt 目录下面的 software 文件夹下面</p>
<h4 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h4><p>解压 JDK 到/opt/module 目录下</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 software]$ tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<h4 id="配置-JDK-环境变量"><a href="#配置-JDK-环境变量" class="headerlink" title="配置 JDK 环境变量"></a><strong>配置</strong> <strong>JDK</strong> <strong>环境变量</strong></h4><ul>
<li><p>新建/etc/profile.d/my_env.sh 文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ sudo vim /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<p>添加如下内容</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#JAVA_HOME</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/module/jdk1.8.0_212</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br></pre></td></tr></table></figure></li>
<li><p>source 一下/etc/profile 文件，让新的环境变量 PATH 生效</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ <span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="测试jdk"><a href="#测试jdk" class="headerlink" title="测试jdk"></a>测试jdk</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop103 opt]$ java -version</span><br><span class="line">java version <span class="string">&quot;1.8.0_212&quot;</span></span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_212-b10)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.212-b10, mixed mode)</span><br></pre></td></tr></table></figure>

<h3 id="安装-Hadoop"><a href="#安装-Hadoop" class="headerlink" title="安装 Hadoop"></a><strong>安装</strong> <strong>Hadoop</strong></h3><p>在 hadoop102 安装 Hadoop</p>
<p>Hadoop 下载地址：<a target="_blank" rel="noopener" href="https://archive.apache.org/dist/hadoop/common/hadoop-3.1.3/">https://archive.apache.org/dist/hadoop/common/hadoop-3.1.3/</a></p>
<h4 id="传输hadoop"><a href="#传输hadoop" class="headerlink" title="传输hadoop"></a>传输hadoop</h4><p>用 XShell 文件传输工具将 hadoop-3.1.3.tar.gz 导入到 opt目录下面的 software 文件夹下面</p>
<h4 id="解压-1"><a href="#解压-1" class="headerlink" title="解压"></a>解压</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 software]$ tar -zxvf hadoop-3.1.3.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure>

<h4 id="添加环境变量"><a href="#添加环境变量" class="headerlink" title="添加环境变量"></a>添加环境变量</h4><ul>
<li><p>获取 Hadoop 安装路径</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop-3.1.3]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.1.3</span><br></pre></td></tr></table></figure></li>
<li><p>打开/etc/profile.d/my_env.sh 文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop-3.1.3]$ sudo vim /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure></li>
<li><p>在 my_env.sh 文件末尾添加如下内容：（shift+g）</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/module/hadoop-3.1.3</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure></li>
<li><p>让修改后的文件生效</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop-3.1.3]$ <span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure></li>
<li><p>测试是否安装成功</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop-3.1.3]$ hadoop version </span><br><span class="line">Hadoop 3.1.3</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="hadoop运行模式"><a href="#hadoop运行模式" class="headerlink" title="hadoop运行模式"></a>hadoop运行模式</h1><p>Hadoop 运行模式包括：<strong>本地模式</strong>、<strong>伪分布式模式</strong>以及<strong>完全分布式模式</strong>。</p>
<p><strong>本地模式</strong>：单机运行，只是用来演示一下官方案例。生产环境不用。</p>
<p><strong>伪分布式模式：</strong>也是单机运行，但是具备 Hadoop 集群的所有功能，一台服务器模拟一个分布式的环境。个别缺钱的公司用来测试，生产环境不用。</p>
<p><strong>完全分布式模式：</strong>多台服务器组成分布式环境。生产环境使用。</p>
<h2 id="本地运行模式"><a href="#本地运行模式" class="headerlink" title="本地运行模式"></a>本地运行模式</h2><ol>
<li><p><strong>创建在</strong> <strong>hadoop-3.1.3</strong> <strong>文件下面创建一个</strong> <strong>wcinput</strong> <strong>文件夹</strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop-3.1.3]$ mkdir wcinput</span><br></pre></td></tr></table></figure></li>
<li><p><strong>在</strong> <strong>wcinput</strong> <strong>文件下创建一个</strong> <strong>word.txt</strong> <strong>文件</strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop-3.1.3]$ <span class="built_in">cd</span> wcinput</span><br></pre></td></tr></table></figure></li>
<li><p><strong>编辑</strong> <strong>word.txt</strong> <strong>文件</strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hadoop yarn</span><br><span class="line">hadoop mapreduce</span><br><span class="line">lvxiaoyi</span><br><span class="line">lvxiaoyi</span><br></pre></td></tr></table></figure></li>
<li><p><strong>回到</strong> <strong>Hadoop</strong> <strong>目录</strong><strong>/opt/module/hadoop-3.1.3</strong></p>
</li>
<li><p><strong>执行程序</strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop-3.1.3]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount wcinput wcoutput</span><br></pre></td></tr></table></figure></li>
<li><p><strong>查看结果</strong></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop-3.1.3]$ cat wcoutput/part-r-00000</span><br><span class="line">lvxiaoyi 2</span><br><span class="line">hadoop 2</span><br><span class="line">mapreduce 1</span><br><span class="line">yarn 1</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="完全分布式运行模式"><a href="#完全分布式运行模式" class="headerlink" title="完全分布式运行模式"></a>完全分布式运行模式</h2><p>分析：</p>
<p>1）准备 3 台客户机（关闭防火墙、静态 IP、主机名称） </p>
<p>2）安装 JDK</p>
<p>3）配置环境变量</p>
<p>4）安装 Hadoop</p>
<p>5）配置环境变量</p>
<p>6）配置集群</p>
<p>7）单点启动</p>
<p>8）配置 ssh</p>
<p>9）群起并测试集群</p>
<h3 id="编写脚本"><a href="#编写脚本" class="headerlink" title="编写脚本"></a>编写脚本</h3><p>编写集群分发脚本 <strong>xsync</strong></p>
<h4 id="scp（secure-copy）安全拷贝"><a href="#scp（secure-copy）安全拷贝" class="headerlink" title="scp（secure copy）安全拷贝"></a>scp（secure copy）安全拷贝</h4><ol>
<li><p>scp 定义</p>
<p>scp 可以实现服务器与服务器之间的数据拷贝。（from server1 to server2） </p>
</li>
<li><p>基本语法</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp  -r  <span class="variable">$pdir</span>/<span class="variable">$fname</span>        <span class="variable">$user</span>@<span class="variable">$host</span>:<span class="variable">$pdir</span>/<span class="variable">$fname</span></span><br><span class="line">命令 递归 要拷贝的文件路径/名称  目的地用户@主机:目的地路径/名称</span><br></pre></td></tr></table></figure></li>
<li><p>案例实操</p>
<p>前提：在 hadoop102、hadoop103、hadoop104 都已经创建好的/opt/module、 /opt/software 两个目录，并且已经把这两个目录修改为 lvxiaoyi:lvxiaoyi</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ sudo chown lvxiaoyi:lvxiaoyi -R /opt/module</span><br></pre></td></tr></table></figure>

<ol>
<li><p>在 hadoop102 上，将 hadoop102 中/opt/module/jdk1.8.0_212 目录拷贝到hadoop103 上。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ scp -r /opt/module/jdk1.8.0_212 </span><br><span class="line"></span><br><span class="line">lvxiaoyi@hadoop103:/opt/module</span><br></pre></td></tr></table></figure></li>
<li><p>在 hadoop103 上，将 hadoop102 中/opt/module/hadoop-3.1.3 目录拷贝到hadoop103 上。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop103 ~]$ scp -r lvxiaoyi@hadoop102:/opt/module/hadoop-3.1.3 /opt/module/</span><br></pre></td></tr></table></figure></li>
<li><p>在 hadoop103 上操作，将 hadoop102 中/opt/module 目录下所有目录拷贝到hadoop104 上。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop103 opt]$ scp -r lvxiaoyi@hadoop102:/opt/module/*lvxiaoyi@hadoop104:/opt/module</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h4 id="rsync-远程同步工具"><a href="#rsync-远程同步工具" class="headerlink" title="rsync 远程同步工具"></a><strong>rsync</strong> 远程同步工具</h4><p>rsync 主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。</p>
<p>rsync 和 scp 区别：用 rsync 做文件的复制要比 scp 的速度快，rsync 只对差异文件做更新。scp 是把所有文件都复制过去。</p>
<ol>
<li><p>基本语法</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rsync   -av     <span class="variable">$pdir</span>/<span class="variable">$fname</span>             <span class="variable">$user</span>@<span class="variable">$host</span>:<span class="variable">$pdir</span>/<span class="variable">$fname</span></span><br><span class="line">命令   选项参数   要拷贝的文件路径/名称     目的地用户@主机:目的地路径/名称</span><br></pre></td></tr></table></figure>

<p>选项参数说明</p>
<table>
<thead>
<tr>
<th>选项</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>-a</td>
<td>归档拷贝</td>
</tr>
<tr>
<td>-v</td>
<td>显示复制过程</td>
</tr>
</tbody></table>
</li>
<li><p>案例实操</p>
<ol>
<li><p>删除 hadoop103 中/opt/module/hadoop-3.1.3/wcinput</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop103 hadoop-3.1.3]$ rm -rf wcinput/</span><br></pre></td></tr></table></figure></li>
<li><p>）同步 hadoop102 中的/opt/module/hadoop-3.1.3 到 hadoop103</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 module]$ rsync -av hadoop-3.1.3/ lvxiaoyi@hadoop103:/opt/module/hadoop-3.1.3/</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h4 id="xsync-集群分发脚本"><a href="#xsync-集群分发脚本" class="headerlink" title="xsync 集群分发脚本"></a>xsync 集群分发脚本</h4><ol>
<li><p>需求：循环复制文件到所有节点的相同目录下</p>
</li>
<li><p>需求分析：</p>
<ol>
<li><p>rsync 命令原始拷贝</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync -av /opt/module lvxiaoyi@hadoop103:/opt/</span><br></pre></td></tr></table></figure></li>
<li><p>期望脚本</p>
<p>xsync 要同步的文件名称</p>
</li>
<li><p>期望脚本在任何路径都能使用（脚本放在声明了全局环境变量的路径）</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ <span class="built_in">echo</span> <span class="variable">$PATH</span></span><br><span class="line">/usr/<span class="built_in">local</span>/bin:/usr/bin:/usr/<span class="built_in">local</span>/sbin:/usr/sbin:/home/lvxiaoyi/.<span class="built_in">local</span>/bin:/home/lvxiaoyi/bin:/opt/module/jdk1.8.0_212/bin</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>脚本实现</p>
<ol>
<li><p>在/home/lvxiaoyi/bin 目录下创建 xsync 文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 opt]$ <span class="built_in">cd</span> /home/lvxiaoyi</span><br><span class="line">[lvxiaoyi@hadoop102 ~]$ mkdir bin</span><br><span class="line">[lvxiaoyi@hadoop102 ~]$ <span class="built_in">cd</span> bin</span><br><span class="line">[lvxiaoyi@hadoop102 bin]$ vim xsync</span><br></pre></td></tr></table></figure>

<p>在该文件中编写如下代码</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#1. 判断参数个数</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -lt 1 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> Not Enough Arguement!</span><br><span class="line">    <span class="built_in">exit</span>;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2. 遍历集群所有机器</span></span><br><span class="line"><span class="keyword">for</span> host <span class="keyword">in</span> hadoop102 hadoop103 hadoop104</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> ====================  <span class="variable">$host</span>  ====================</span><br><span class="line">    <span class="comment">#3. 遍历所有目录，挨个发送</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> file <span class="keyword">in</span> <span class="variable">$@</span></span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        <span class="comment">#4. 判断文件是否存在</span></span><br><span class="line">        <span class="keyword">if</span> [ -e <span class="variable">$file</span> ]</span><br><span class="line">            <span class="keyword">then</span></span><br><span class="line">                <span class="comment">#5. 获取父目录</span></span><br><span class="line">                pdir=$(<span class="built_in">cd</span> -P $(dirname <span class="variable">$file</span>); <span class="built_in">pwd</span>)</span><br><span class="line"></span><br><span class="line">                <span class="comment">#6. 获取当前文件的名称</span></span><br><span class="line">                fname=$(basename <span class="variable">$file</span>)</span><br><span class="line">                ssh <span class="variable">$host</span> <span class="string">&quot;mkdir -p <span class="variable">$pdir</span>&quot;</span></span><br><span class="line">                rsync -av <span class="variable">$pdir</span>/<span class="variable">$fname</span> <span class="variable">$host</span>:<span class="variable">$pdir</span></span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                <span class="built_in">echo</span> <span class="variable">$file</span> does not exists!</span><br><span class="line">        <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></li>
<li><p>修改脚本 xsync 具有执行权限</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 bin]$ chmod +x xsync</span><br></pre></td></tr></table></figure></li>
<li><p>测试脚本</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ xsync /home/lvxiaoyi/bin</span><br></pre></td></tr></table></figure></li>
<li><p>将脚本复制到/bin中，以便全局调用</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 bin]$ sudo cp xsync /bin/</span><br></pre></td></tr></table></figure></li>
<li><p>同步环境变量配置（root所有者）</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ sudo ./bin/xsync /etc/profile.d/my_env.sh</span><br></pre></td></tr></table></figure>

<p>让环境变量生效</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop103 bin]$ <span class="built_in">source</span> /etc/profile</span><br><span class="line">[lvxiaoyi@hadoop104 opt]$ <span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h3 id="SSH无密登录配置"><a href="#SSH无密登录配置" class="headerlink" title="SSH无密登录配置"></a><code>SSH</code>无密登录配置</h3><h4 id="配置ssh"><a href="#配置ssh" class="headerlink" title="配置ssh"></a>配置ssh</h4><ol>
<li><p>基本语法</p>
<p>ssh另一台电脑的IP地址</p>
</li>
<li><p>sh连接时出现Host key verification failed的解决方法</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ ssh hadoop103</span><br></pre></td></tr></table></figure>

<p>如果出现如下内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Are you sure you want to continue connecting (yes/no)?</span><br></pre></td></tr></table></figure>

<p>输入yes，并回车</p>
</li>
<li><p>退回到hadoop102</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop103 ~]$ exit</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="无密钥配置"><a href="#无密钥配置" class="headerlink" title="无密钥配置"></a>无密钥配置</h4><ol>
<li><p>免密登录原理 </p>
<p>这个视频是讲解是错误的，正确的流程应该是下面的</p>
<ol>
<li>在A上生成公钥私钥。 </li>
<li>将公钥拷贝给server B，要重命名成authorized_keys(从英文名就知道含义了) </li>
<li>Server A向Server B发送一个连接请求。 </li>
<li>Server B得到Server A的信息后，==在authorized_key中查找==，==如果有相应的用户名和IP，则随机生成一个字符串==，并用Server A的公钥加密，发送给Server A。 </li>
<li>==Server A得到Server B发来的消息后，使用私钥进行解密，然后将解密后的字符串发送给Server B==。Server B进行和生成的对比，如果一致，则允许免登录 </li>
</ol>
<p>总之：A要免密码登录到B，B首先要拥有A的公钥，然后B要做一次加密验证。对于非对称加密，公钥加密的密文不能公钥解开，只能私钥解开。</p>
</li>
<li><p>生成公钥和私钥</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 .ssh]$ ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>

<p>然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）</p>
</li>
<li><p>将公钥拷贝到要免密登录的目标机器上</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 .ssh]$ ssh-copy-id hadoop102</span><br><span class="line">[lvxiaoyi@hadoop102 .ssh]$ ssh-copy-id hadoop103</span><br><span class="line">[lvxiaoyi@hadoop102 .ssh]$ ssh-copy-id hadoop104</span><br></pre></td></tr></table></figure>

<p>注意：</p>
<p>还需要在hadoop103上采用lvxiaoyi账号配置一下无密登录到hadoop102、hadoop103、hadoop104服务器上。</p>
<p>还需要在hadoop104上采用lvxiaoyi账号配置一下无密登录到hadoop102、hadoop103、hadoop104服务器上。</p>
<p>还需要在hadoop102上采用root账号，配置一下无密登录到hadoop102、hadoop103、hadoop104；</p>
</li>
<li><p>（~/.ssh）的文件功能解释</p>
<table>
<thead>
<tr>
<th>known_hosts</th>
<th>记录ssh访问过计算机的公钥（public key）</th>
</tr>
</thead>
<tbody><tr>
<td>id_rsa</td>
<td>生成的私钥</td>
</tr>
<tr>
<td>id_rsa.pub</td>
<td>生成的公钥</td>
</tr>
<tr>
<td>authorized_keys</td>
<td>存放授权过的无密登录服务器公钥</td>
</tr>
</tbody></table>
</li>
</ol>
<h3 id="集群配置"><a href="#集群配置" class="headerlink" title="集群配置"></a>集群配置</h3><h4 id="集群部署规划"><a href="#集群部署规划" class="headerlink" title="集群部署规划"></a>集群部署规划</h4><p>==注意：==</p>
<ul>
<li>NameNode和SecondaryNameNode不要安装在同一台服务器</li>
<li>ResourceManager也很消耗内存，不要和NameNode、SecondaryNameNode配置在同一台机器上。</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>hadoop102</th>
<th>hadoop103</th>
<th>hadoop104</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>NameNodeDataNode</td>
<td>DataNode</td>
<td>SecondaryNameNodeDataNode</td>
</tr>
<tr>
<td>YARN</td>
<td>NodeManager</td>
<td>ResourceManagerNodeManager</td>
<td>NodeManager</td>
</tr>
</tbody></table>
<h4 id="配置文件说明"><a href="#配置文件说明" class="headerlink" title="配置文件说明"></a>配置文件说明</h4><p>Hadoop配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。</p>
<ul>
<li><p>默认配置文件：</p>
<table>
<thead>
<tr>
<th>要获取的默认文件</th>
<th>文件存放在Hadoop的jar包中的位置</th>
</tr>
</thead>
<tbody><tr>
<td>[core-default.xml]</td>
<td>hadoop-common-3.1.3.jar/core-default.xml</td>
</tr>
<tr>
<td>[hdfs-default.xml]</td>
<td>hadoop-hdfs-3.1.3.jar/hdfs-default.xml</td>
</tr>
<tr>
<td>[yarn-default.xml]</td>
<td>hadoop-yarn-common-3.1.3.jar/yarn-default.xml</td>
</tr>
<tr>
<td>[mapred-default.xml]</td>
<td>hadoop-mapreduce-client-core-3.1.3.jar/mapred-default.xml</td>
</tr>
</tbody></table>
</li>
<li><p>自定义配置文件：</p>
<p>core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml四个配置文件存放在$HADOOP_HOME/etc/hadoop这个路径上，用户可以根据项目需求重新进行修改配置。</p>
</li>
</ul>
<h4 id="配置集群"><a href="#配置集群" class="headerlink" title="配置集群"></a>配置集群</h4><ol>
<li><p>核心配置文件</p>
<p>配置core-site.xml</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ <span class="built_in">cd</span> <span class="variable">$HADOOP_HOME</span>/etc/hadoop</span><br><span class="line">[lvxiaoyi@hadoop102 hadoop]$ vim core-site.xml</span><br></pre></td></tr></table></figure>

<p>文件内容如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定NameNode的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop102:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 指定hadoop数据的存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.1.3/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 配置HDFS网页登录使用的静态用户为lvxiaoyi --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>lvxiaoyi<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>HDFS配置文件</p>
<p>配置hdfs-site.xml</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop]$ vim hdfs-site.xml</span><br></pre></td></tr></table></figure>

<p>文件内容如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- nn web端访问地址--&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 2nn web端访问地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>YARN配置文件</p>
<p>配置yarn-site.xml</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop]$ vim yarn-site.xml</span><br></pre></td></tr></table></figure>

<p>文件内容如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定MR走shuffle --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 指定ResourceManager的地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 环境变量的继承 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>MapReduce配置文件</p>
<p>配置mapred-site.xml</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop]$ vim mapred-site.xml</span><br></pre></td></tr></table></figure>

<p>文件内容如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="comment">&lt;!-- 指定MapReduce程序运行在Yarn上 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="分配配置"><a href="#分配配置" class="headerlink" title="分配配置"></a>分配配置</h4><p>在集群上分发配置好的Hadoop配置文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop]$ xsync /opt/module/hadoop-3.1.3/etc/hadoop/</span><br></pre></td></tr></table></figure>

<p>去103和104上查看文件分发情况</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop103 ~]$ cat /opt/module/hadoop-3.1.3/etc/hadoop/core-site.xml</span><br><span class="line">[lvxiaoyi@hadoop104 ~]$ cat /opt/module/hadoop-3.1.3/etc/hadoop/core-site.xml</span><br></pre></td></tr></table></figure>

<h3 id="群起集群"><a href="#群起集群" class="headerlink" title="群起集群"></a>群起集群</h3><h4 id="配置workers"><a href="#配置workers" class="headerlink" title="配置workers"></a>配置workers</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop]$ vim /opt/module/hadoop-3.1.3/etc/hadoop/workers</span><br></pre></td></tr></table></figure>

<p>在该文件中增加如下内容：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br></pre></td></tr></table></figure>

<p>注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。</p>
<p>同步所有节点配置文件：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop]$ xsync /opt/module/hadoop-3.1.3/etc</span><br></pre></td></tr></table></figure>

<h4 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h4><ol>
<li><p>如果集群是第一次启动，需要在hadoop102节点格式化NameNode（注意：格式化NameNode，会产生新的集群id，导致NameNode和DataNode的集群id不一致，集群找不到已往数据。如果集群在运行过程中报错，需要重新格式化NameNode的话，一定要先停止namenode和datanode进程，并且要删除所有机器的data和logs目录，然后再进行格式化。）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop-3.1.3]$ hdfs namenode -format</span><br></pre></td></tr></table></figure></li>
<li><p>启动HDFS</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop-3.1.3]$ sbin/start-dfs.sh</span><br></pre></td></tr></table></figure></li>
<li><p>在配置了ResourceManager的节点（hadoop103）启动YARN</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop103 hadoop-3.1.3]$ sbin/start-yarn.sh</span><br></pre></td></tr></table></figure></li>
<li><p>Web端查看HDFS的NameNode</p>
<p>浏览器中输入：<a target="_blank" rel="noopener" href="http://hadoop102:9870/">http://hadoop102:9870</a></p>
<p>查看HDFS上存储的数据信息</p>
</li>
<li><p>Web端查看YARN的ResourceManager</p>
<p>浏览器中输入：<a target="_blank" rel="noopener" href="http://hadoop103:8088/">http://hadoop103:8088</a></p>
<p>查看YARN上运行的Job信息</p>
</li>
</ol>
<h4 id="集群基本测试"><a href="#集群基本测试" class="headerlink" title="集群基本测试"></a>集群基本测试</h4><ol>
<li><p>上传文件到集群</p>
<p>上传小文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ hadoop fs -mkdir /input</span><br><span class="line">[lvxiaoyi@hadoop102 ~]$ hadoop fs -put <span class="variable">$HADOOP_HOME</span>/wcinput/word.txt /input</span><br></pre></td></tr></table></figure>

<p>上传大文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ hadoop fs -put  /opt/software/jdk-8u212-linux-x64.tar.gz  /</span><br></pre></td></tr></table></figure></li>
<li><p>上传文件后查看文件存放在什么位置</p>
<p>查看HDFS文件存储路径</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 subdir0]$ <span class="built_in">pwd</span></span><br><span class="line">/opt/module/hadoop-3.1.3/data/dfs/data/current/BP-1436128598-192.168.10.102-1610603650062/current/finalized/subdir0/subdir0</span><br></pre></td></tr></table></figure>

<p>查看HDFS在磁盘存储文件内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 subdir0]$ cat blk_1073741825</span><br><span class="line">hadoop yarn</span><br><span class="line">hadoop mapreduce </span><br><span class="line">lvxiaoyi</span><br><span class="line">lvxiaoyi</span><br></pre></td></tr></table></figure></li>
<li><p>拼接</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">-rw-rw-r--. 1 lvxiaoyi lvxiaoyi 134217728 5月  23 16:01 blk_1073741836</span><br><span class="line">-rw-rw-r--. 1 lvxiaoyi lvxiaoyi   1048583 5月  23 16:01 blk_1073741836_1012.meta</span><br><span class="line">-rw-rw-r--. 1 lvxiaoyi lvxiaoyi  63439959 5月  23 16:01 blk_1073741837</span><br><span class="line">-rw-rw-r--. 1 lvxiaoyi lvxiaoyi    495635 5月  23 16:01 blk_1073741837_1013.meta</span><br><span class="line"></span><br><span class="line">[lvxiaoyi@hadoop102 subdir0]$ cat blk_1073741836&gt;&gt;tmp.tar.gz</span><br><span class="line">[lvxiaoyi@hadoop102 subdir0]$ cat blk_1073741837&gt;&gt;tmp.tar.gz</span><br><span class="line">[lvxiaoyi@hadoop102 subdir0]$ tar -zxvf tmp.tar.gz</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
<li><p>下载</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop104 software]$ hadoop fs -get /jdk-8u212-linux-x64.tar.gz ./</span><br></pre></td></tr></table></figure></li>
<li><p>执行wordcount程序</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop-3.1.3]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /output</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="配置历史服务器"><a href="#配置历史服务器" class="headerlink" title="配置历史服务器"></a>配置历史服务器</h3><p>为了查看程序的历史运行情况，需要配置一下历史服务器。具体配置步骤如下：</p>
<ol>
<li><p>配置mapred-site.xml</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop]$ vim mapred-site.xml</span><br></pre></td></tr></table></figure>

<p>在该文件里面增加如下配置。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 历史服务器端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">   </span><br><span class="line"><span class="comment">&lt;!-- 历史服务器web端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>分发配置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop]$ xsync $HADOOP_HOME/etc/hadoop/mapred-site.xml</span><br></pre></td></tr></table></figure></li>
<li><p>在hadoop102启动历史服务器</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop]$ mapred --daemon start historyserver</span><br></pre></td></tr></table></figure></li>
<li><p>查看历史服务器是否启动</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop]$ jps</span><br></pre></td></tr></table></figure></li>
<li><p>查看JobHistory</p>
<p><a target="_blank" rel="noopener" href="http://hadoop102:19888/jobhistory">http://hadoop102:19888/jobhistory</a></p>
</li>
</ol>
<h3 id="配置日志的聚集"><a href="#配置日志的聚集" class="headerlink" title="配置日志的聚集"></a>配置日志的聚集</h3><p>日志聚集概念：应用运行完成以后，将程序运行日志信息上传到HDFS系统上。</p>
<p>日志聚集功能好处：可以方便的查看到程序运行详情，方便开发调试。</p>
<p>注意：开启日志聚集功能，需要重新启动NodeManager 、ResourceManager和HistoryServer。</p>
<p>开启日志聚集功能具体步骤如下：</p>
<ol>
<li><p>配置yarn-site.xml</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop]$ vim yarn-site.xml</span><br></pre></td></tr></table></figure>

<p>在该文件里面增加如下配置</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 开启日志聚集功能 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 设置日志聚集服务器地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://hadoop102:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 设置日志保留时间为7天 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li>
<li><p>分发配置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop]$ xsync $HADOOP_HOME/etc/hadoop/yarn-site.xml</span><br></pre></td></tr></table></figure></li>
<li><p>关闭NodeManager 、ResourceManager和HistoryServer</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop103 hadoop-3.1.3]$ sbin/stop-yarn.sh</span><br><span class="line">[lvxiaoyi@hadoop103 hadoop-3.1.3]$ mapred --daemon stop historyserver</span><br></pre></td></tr></table></figure></li>
<li><p>启动NodeManager 、ResourceManage和HistoryServer</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ mapred --daemon start historyserver</span><br></pre></td></tr></table></figure></li>
<li><p>删除HDFS上已经存在的输出文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ hadoop fs -rm -r /output</span><br></pre></td></tr></table></figure></li>
<li><p>执行WordCount程序</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 hadoop-3.1.3]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /output</span><br></pre></td></tr></table></figure></li>
<li><p>查看日志</p>
<ol>
<li><p>历史服务器地址</p>
<p><a target="_blank" rel="noopener" href="http://hadoop102:19888/jobhistory">http://hadoop102:19888/jobhistory</a></p>
</li>
<li><p>历史任务列表</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211030085907609.png/lvxiaoyi" alt="image-20211030085907609"></p>
</li>
<li><p>查看任务运行日志</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211030085838324.png/lvxiaoyi" alt="image-20211030085838324"></p>
</li>
<li><p>运行日志详情</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211030085925648.png/lvxiaoyi" alt="image-20211030085925648"></p>
</li>
</ol>
</li>
</ol>
<h3 id="集群启动-停止方式总结"><a href="#集群启动-停止方式总结" class="headerlink" title="集群启动/停止方式总结"></a>集群启动/停止方式总结</h3><ol>
<li><p>各个模块分开启动停止（配置ssh是前提）常用</p>
<p>整体启动/停止HDFS</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh/stop-dfs.sh</span><br></pre></td></tr></table></figure>

<p>整体启动/停止YARN</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-yarn.sh/stop-yarn.sh</span><br></pre></td></tr></table></figure></li>
<li><p>各个服务组件逐一启动停止</p>
<p>分别启动/停止HDFS组件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs --daemon start/stop namenode/datanode/secondarynamenode</span><br></pre></td></tr></table></figure>

<p>启动/停止YARN</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn --daemon start/stop  resourcemanager/nodemanager</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="编写Hadoop集群常用脚本"><a href="#编写Hadoop集群常用脚本" class="headerlink" title="编写Hadoop集群常用脚本"></a>编写Hadoop集群常用脚本</h3><ol>
<li><p>Hadoop集群启停脚本（包含HDFS，Yarn，Historyserver）：myhadoop.sh</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ cd /home/lvxiaoyi/bin</span><br><span class="line">[lvxiaoyi@hadoop102 bin]$ vim myhadoop.sh</span><br></pre></td></tr></table></figure>

<p>输入如下内容</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -lt 1 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;No Args Input...&quot;</span></span><br><span class="line">    <span class="built_in">exit</span> ;</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line"><span class="string">&quot;start&quot;</span>)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; =================== 启动 hadoop集群 ===================&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 启动 hdfs ---------------&quot;</span></span><br><span class="line">        ssh hadoop102 <span class="string">&quot;/opt/module/hadoop-3.1.3/sbin/start-dfs.sh&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 启动 yarn ---------------&quot;</span></span><br><span class="line">        ssh hadoop103 <span class="string">&quot;/opt/module/hadoop-3.1.3/sbin/start-yarn.sh&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 启动 historyserver ---------------&quot;</span></span><br><span class="line">        ssh hadoop102 <span class="string">&quot;/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver&quot;</span></span><br><span class="line">;;</span><br><span class="line"><span class="string">&quot;stop&quot;</span>)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; =================== 关闭 hadoop集群 ===================&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 关闭 historyserver ---------------&quot;</span></span><br><span class="line">        ssh hadoop102 <span class="string">&quot;/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 关闭 yarn ---------------&quot;</span></span><br><span class="line">        ssh hadoop103 <span class="string">&quot;/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot; --------------- 关闭 hdfs ---------------&quot;</span></span><br><span class="line">        ssh hadoop102 <span class="string">&quot;/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh&quot;</span></span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Input Args Error...&quot;</span></span><br><span class="line">;;</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure>

<p>保存后退出，然后赋予脚本执行权限</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 bin]$ chmod +x myhadoop.sh</span><br></pre></td></tr></table></figure></li>
<li><p>查看三台服务器Java进程脚本：jpsall</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ cd /home/lvxiaoyi/bin</span><br><span class="line">[lvxiaoyi@hadoop102 bin]$ vim jpsall</span><br></pre></td></tr></table></figure>

<p>输入如下内容</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> host <span class="keyword">in</span> hadoop102 hadoop103 hadoop104</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> =============== <span class="variable">$host</span> ===============</span><br><span class="line">        ssh <span class="variable">$host</span> jps </span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<p>保存后退出，然后赋予脚本执行权限</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 bin]$ chmod +x jpsall</span><br></pre></td></tr></table></figure></li>
<li><p>分发/home/lvxiaoyi/bin目录，保证自定义脚本在三台机器上都可以使用</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ xsync /home/lvxiaoyi/bin/</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="常用端口号说明"><a href="#常用端口号说明" class="headerlink" title="常用端口号说明"></a>常用端口号说明</h3><table>
<thead>
<tr>
<th>端口名称</th>
<th>Hadoop2.x</th>
<th>Hadoop3.x</th>
</tr>
</thead>
<tbody><tr>
<td>NameNode内部通信端口</td>
<td>8020 / 9000</td>
<td>8020 / 9000/9820</td>
</tr>
<tr>
<td>NameNode HTTP UI</td>
<td>50070</td>
<td>9870</td>
</tr>
<tr>
<td>MapReduce查看执行任务端口</td>
<td>8088</td>
<td>8088</td>
</tr>
<tr>
<td>历史服务器通信端口</td>
<td>19888</td>
<td>19888</td>
</tr>
</tbody></table>
<p>3.0中slaves替换为workers</p>
<h3 id="集群时间同步"><a href="#集群时间同步" class="headerlink" title="集群时间同步"></a>集群时间同步</h3><p>如果服务器在公网环境（能连接外网），可以不采用集群时间同步，因为服务器会定期和公网时间进行校准；</p>
<p>如果服务器在内网环境，必须要配置集群时间同步，否则时间久了，会产生时间偏差，导致集群执行任务时间不同步。</p>
<ol>
<li><p>需求</p>
<p>找一个机器，作为时间服务器，所有的机器与这台集群时间进行定时的同步，生产环境根据任务对时间的准确程度要求周期同步。测试环境为了尽快看到效果，采用1分钟同步一次。</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211029174755911.png/lvxiaoyi" alt="image-20211029174755911" style="zoom: 67%;" /></li>
<li><p>时间服务器配置（必须root用户）</p>
<ol>
<li><p>查看所有节点ntpd服务状态和开机自启动状态</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ sudo systemctl status ntpd</span><br><span class="line">[lvxiaoyi@hadoop102 ~]$ sudo systemctl start ntpd</span><br><span class="line">[lvxiaoyi@hadoop102 ~]$ sudo systemctl is-enabled ntpd</span><br></pre></td></tr></table></figure></li>
<li><p>修改hadoop102的ntp.conf配置文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ sudo vim /etc/ntp.conf</span><br></pre></td></tr></table></figure>

<p>修改内容如下</p>
<p>修改1（授权192.168.10.0-192.168.10.255网段上的所有机器可以从这台机器上查询和同步时间）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#restrict 192.168.10.0 mask 255.255.255.0 nomodify notrap</span><br><span class="line">为restrict 192.168.10.0 mask 255.255.255.0 nomodify notrap</span><br></pre></td></tr></table></figure>

<p>修改2（集群在局域网中，不使用其他互联网上的时间）</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">server 0.centos.pool.ntp.org iburst</span><br><span class="line">server 1.centos.pool.ntp.org iburst</span><br><span class="line">server 2.centos.pool.ntp.org iburst</span><br><span class="line">server 3.centos.pool.ntp.org iburst</span><br><span class="line"></span><br><span class="line">为</span><br><span class="line"><span class="comment">#server 0.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="comment">#server 1.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="comment">#server 2.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="comment">#server 3.centos.pool.ntp.org iburst</span></span><br></pre></td></tr></table></figure>

<p>添加3（当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">server 127.127.1.0</span><br><span class="line">fudge 127.127.1.0 stratum 10</span><br></pre></td></tr></table></figure></li>
<li><p>修改hadoop102的/etc/sysconfig/ntpd 文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ sudo vim /etc/sysconfig/ntpd</span><br></pre></td></tr></table></figure>

<p>增加内容如下（让硬件时间与系统时间一起同步）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SYNC_HWCLOCK=yes</span><br></pre></td></tr></table></figure></li>
<li><p>重新启动ntpd服务</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ sudo systemctl start ntpd</span><br></pre></td></tr></table></figure></li>
<li><p>设置ntpd服务开机启动</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 ~]$ sudo systemctl enable ntpd</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>其他机器配置（必须root用户）</p>
<ol>
<li><p>关闭所有节点上ntp服务和自启动</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop103 ~]$ sudo systemctl stop ntpd</span><br><span class="line">[lvxiaoyi@hadoop103 ~]$ sudo systemctl disable ntpd</span><br><span class="line">[lvxiaoyi@hadoop104 ~]$ sudo systemctl stop ntpd</span><br><span class="line">[lvxiaoyi@hadoop104 ~]$ sudo systemctl disable ntpd</span><br></pre></td></tr></table></figure></li>
<li><p>在其他机器配置1分钟与时间服务器同步一次.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop103 ~]$ sudo crontab -e</span><br></pre></td></tr></table></figure>

<p>编写定时任务如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/1 * * * * /usr/sbin/ntpdate hadoop102</span><br></pre></td></tr></table></figure></li>
<li><p>修改任意机器时间</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop103 ~]$ sudo date -s &quot;2021-9-11 11:11:11&quot;</span><br></pre></td></tr></table></figure></li>
<li><p>1分钟后查看机器是否与时间服务器同步</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop103 ~]$ sudo date</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><ol>
<li><p>防火墙没关闭、或者没有启动YARN</p>
<p>INFO client.RMProxy: Connecting to ResourceManager at hadoop108/192.168.10.108:8032*</p>
</li>
<li><p>主机名称配置错误</p>
</li>
<li><p>IP地址配置错误</p>
</li>
<li><p>ssh没有配置好</p>
</li>
<li><p>root用户和lvxiaoyi两个用户启动集群不统一</p>
</li>
<li><p>配置文件修改不细心</p>
</li>
<li><p>不识别主机名称</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">java.net.UnknownHostException: hadoop102: hadoop102</span><br><span class="line">        at java.net.InetAddress.getLocalHost(InetAddress.java:<span class="number">1475</span>)</span><br><span class="line">        at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:<span class="number">146</span>)</span><br><span class="line">        at org.apache.hadoop.mapreduce.Job$<span class="number">10.</span>run(Job.java:<span class="number">1290</span>)</span><br><span class="line">        at org.apache.hadoop.mapreduce.Job$<span class="number">10.</span>run(Job.java:<span class="number">1287</span>)</span><br><span class="line">        at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">at javax.security.auth.Subject.doAs(Subject.java:<span class="number">415</span>)</span><br></pre></td></tr></table></figure></li>
</ol>
<p>​        解决办法： </p>
<ol>
<li><p>在/etc/hosts文件中添加192.168.10.102 hadoop102</p>
</li>
<li><p>主机名称不要起hadoop  hadoop000等特殊名称</p>
</li>
<li><p>DataNode和NameNode进程同时只能工作一个。</p>
</li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211029175425854.png/lvxiaoyi" alt="image-20211029175425854"></p>
<ol start="9">
<li><p>执行命令不生效，粘贴Word中命令时，遇到-和长–没区分开。导致命令失效</p>
<p>解决办法：尽量不要粘贴Word中代码。</p>
</li>
<li><p>jps发现进程已经没有，但是重新启动集群，提示进程已经开启。</p>
<p>原因是在Linux的根目录下/tmp目录中存在启动的进程临时文件，将集群相关进程删除掉，再重新启动集群。</p>
</li>
<li><p>jps不生效</p>
<p>原因：全局变量hadoop java没有生效。解决办法：需要source /etc/profile文件。</p>
</li>
<li><p>8088端口连接不上</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[lvxiaoyi@hadoop102 桌面]$ cat /etc/hosts</span><br></pre></td></tr></table></figure>

<p>​    注释掉如下代码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#127.0.0.1  localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line"></span><br><span class="line">#::1     hadoop102</span><br></pre></td></tr></table></figure>

</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://lvxiaoyi.top">lvxiaoyi</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://lvxiaoyi.top/136e7b9b.html">https://lvxiaoyi.top/136e7b9b.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://lvxiaoyi.top" target="_blank">吕小医's BLOG</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></div><div class="post_share"><div class="social-share" data-image="https://img.lvxiaoyi.top/typora-img/image-20211028174657424.png/lvxiaoyi" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/5eb2dc8b.html"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211028174657424.png/lvxiaoyi" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">hadoop高级-1生产调优</div></div></a></div><div class="next-post pull-right"><a href="/56b3fe2c.html"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211028174657424.png/lvxiaoyi" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">hadoop基础-2HDFS</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/5eb2dc8b.html" title="hadoop基础-3Yarn"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211028174657424.png/lvxiaoyi" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-12</div><div class="title">hadoop基础-3Yarn</div></div></a></div><div><a href="/bc13a2ae.html" title="HBase基础"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211028174657424.png/lvxiaoyi" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-12</div><div class="title">HBase基础</div></div></a></div><div><a href="/1d83a7d1.html" title="Hive基础-1"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211028174657424.png/lvxiaoyi" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-12</div><div class="title">Hive基础-1</div></div></a></div><div><a href="/9cbb2d93.html" title="hive基础-2"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211028174657424.png/lvxiaoyi" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-12</div><div class="title">hive基础-2</div></div></a></div><div><a href="/6362a21d.html" title="Scala基础-1"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/202111082146936.png/lvxiaoyi" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-12</div><div class="title">Scala基础-1</div></div></a></div><div><a href="/beeb1f38.html" title="Kafka基础"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic2.zhimg.com/v2-9964d2894516902605191817111ec781_r.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-12</div><div class="title">Kafka基础</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://p0.meituan.net/csc/8a1b1d488e6a8ab5108c9c78f36b3a1776955.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">lvxiaoyi</div><div class="author-info__description">ISFP到ESFJ</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">205</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">27</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">51</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/lvxiaoyi"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">冲鸭！内卷起来了兄弟</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#hadoop%E5%9F%BA%E7%A1%80-1"><span class="toc-number">1.</span> <span class="toc-text">hadoop基础-1</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0"><span class="toc-number">2.</span> <span class="toc-text">概述</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%91%E5%B1%95"><span class="toc-number">2.1.</span> <span class="toc-text">发展</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">2.1.1.</span> <span class="toc-text">是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2"><span class="toc-number">2.1.2.</span> <span class="toc-text">发展历史</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E5%A4%A7%E7%89%88%E6%9C%AC"><span class="toc-number">2.1.3.</span> <span class="toc-text">三大版本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E5%8A%BF"><span class="toc-number">2.1.4.</span> <span class="toc-text">优势</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#hadoop%E7%BB%84%E6%88%90"><span class="toc-number">2.2.</span> <span class="toc-text">hadoop组成</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0"><span class="toc-number">2.2.1.</span> <span class="toc-text">HDFS架构概述</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%84%E6%88%90"><span class="toc-number">2.2.1.1.</span> <span class="toc-text">组成</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#YARN%E6%A6%82%E8%BF%B0"><span class="toc-number">2.2.2.</span> <span class="toc-text">YARN概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce-%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0"><span class="toc-number">2.2.3.</span> <span class="toc-text">MapReduce 架构概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS%E3%80%81YARN%E3%80%81MapReduce-%E4%B8%89%E8%80%85%E5%85%B3%E7%B3%BB"><span class="toc-number">2.2.4.</span> <span class="toc-text">HDFS、YARN、MapReduce 三者关系</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E7%94%9F%E6%80%81%E4%BD%93%E7%B3%BB"><span class="toc-number">2.3.</span> <span class="toc-text">大数据技术生态体系</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B3%BB%E7%BB%9F%E6%A1%86%E6%9E%B6%E5%9B%BE"><span class="toc-number">2.4.</span> <span class="toc-text">系统框架图</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA"><span class="toc-number">3.</span> <span class="toc-text">hadoop环境搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E6%9D%BF%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="toc-number">3.1.</span> <span class="toc-text">模板虚拟机环境准备</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85%E6%A8%A1%E6%9D%BF%E8%99%9A%E6%8B%9F%E6%9C%BA"><span class="toc-number">3.1.1.</span> <span class="toc-text">安装模板虚拟机</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#hadoop100-%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%85%8D%E7%BD%AE"><span class="toc-number">3.1.1.1.</span> <span class="toc-text">hadoop100 虚拟机配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99"><span class="toc-number">3.1.1.2.</span> <span class="toc-text">关闭防火墙</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA-lvxiaoyi-%E7%94%A8%E6%88%B7"><span class="toc-number">3.1.1.3.</span> <span class="toc-text">创建 lvxiaoyi 用户</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AE%E6%9D%83%E9%99%90"><span class="toc-number">3.1.1.4.</span> <span class="toc-text">设置权限</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E8%BD%AF%E4%BB%B6%E5%AD%98%E6%94%BE%E4%BD%8D%E7%BD%AE"><span class="toc-number">3.1.1.5.</span> <span class="toc-text">创建软件存放位置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%B8%E8%BD%BD%E8%87%AA%E5%B8%A6jdk"><span class="toc-number">3.1.1.6.</span> <span class="toc-text">卸载自带jdk</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%87%8D%E5%90%AF"><span class="toc-number">3.1.1.7.</span> <span class="toc-text">重启</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%8B%E9%9A%86%E8%99%9A%E6%8B%9F%E6%9C%BA"><span class="toc-number">3.1.2.</span> <span class="toc-text">克隆虚拟机</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%8B%E9%9A%86"><span class="toc-number">3.1.2.1.</span> <span class="toc-text">克隆</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9ip"><span class="toc-number">3.1.2.2.</span> <span class="toc-text">修改ip</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9%E5%85%8B%E9%9A%86%E4%B8%BB%E6%9C%BA%E5%90%8D"><span class="toc-number">3.1.2.3.</span> <span class="toc-text">修改克隆主机名</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85-JDK"><span class="toc-number">3.1.3.</span> <span class="toc-text">安装 JDK</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%B8%E8%BD%BD%E7%8E%B0%E6%9C%89-JDK"><span class="toc-number">3.1.3.1.</span> <span class="toc-text">卸载现有 JDK</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%A0%E8%BE%93jdk%E6%96%87%E4%BB%B6"><span class="toc-number">3.1.3.2.</span> <span class="toc-text">传输jdk文件</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E5%8E%8B"><span class="toc-number">3.1.3.3.</span> <span class="toc-text">解压</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE-JDK-%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">3.1.3.4.</span> <span class="toc-text">配置 JDK 环境变量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95jdk"><span class="toc-number">3.1.3.5.</span> <span class="toc-text">测试jdk</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85-Hadoop"><span class="toc-number">3.1.4.</span> <span class="toc-text">安装 Hadoop</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%A0%E8%BE%93hadoop"><span class="toc-number">3.1.4.1.</span> <span class="toc-text">传输hadoop</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E5%8E%8B-1"><span class="toc-number">3.1.4.2.</span> <span class="toc-text">解压</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">3.1.4.3.</span> <span class="toc-text">添加环境变量</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#hadoop%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="toc-number">4.</span> <span class="toc-text">hadoop运行模式</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%AC%E5%9C%B0%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="toc-number">4.1.</span> <span class="toc-text">本地运行模式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F"><span class="toc-number">4.2.</span> <span class="toc-text">完全分布式运行模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E5%86%99%E8%84%9A%E6%9C%AC"><span class="toc-number">4.2.1.</span> <span class="toc-text">编写脚本</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#scp%EF%BC%88secure-copy%EF%BC%89%E5%AE%89%E5%85%A8%E6%8B%B7%E8%B4%9D"><span class="toc-number">4.2.1.1.</span> <span class="toc-text">scp（secure copy）安全拷贝</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#rsync-%E8%BF%9C%E7%A8%8B%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7"><span class="toc-number">4.2.1.2.</span> <span class="toc-text">rsync 远程同步工具</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#xsync-%E9%9B%86%E7%BE%A4%E5%88%86%E5%8F%91%E8%84%9A%E6%9C%AC"><span class="toc-number">4.2.1.3.</span> <span class="toc-text">xsync 集群分发脚本</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#SSH%E6%97%A0%E5%AF%86%E7%99%BB%E5%BD%95%E9%85%8D%E7%BD%AE"><span class="toc-number">4.2.2.</span> <span class="toc-text">SSH无密登录配置</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEssh"><span class="toc-number">4.2.2.1.</span> <span class="toc-text">配置ssh</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%97%A0%E5%AF%86%E9%92%A5%E9%85%8D%E7%BD%AE"><span class="toc-number">4.2.2.2.</span> <span class="toc-text">无密钥配置</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE"><span class="toc-number">4.2.3.</span> <span class="toc-text">集群配置</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E8%A7%84%E5%88%92"><span class="toc-number">4.2.3.1.</span> <span class="toc-text">集群部署规划</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E"><span class="toc-number">4.2.3.2.</span> <span class="toc-text">配置文件说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E9%9B%86%E7%BE%A4"><span class="toc-number">4.2.3.3.</span> <span class="toc-text">配置集群</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E9%85%8D%E9%85%8D%E7%BD%AE"><span class="toc-number">4.2.3.4.</span> <span class="toc-text">分配配置</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BE%A4%E8%B5%B7%E9%9B%86%E7%BE%A4"><span class="toc-number">4.2.4.</span> <span class="toc-text">群起集群</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEworkers"><span class="toc-number">4.2.4.1.</span> <span class="toc-text">配置workers</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%90%AF%E5%8A%A8%E9%9B%86%E7%BE%A4"><span class="toc-number">4.2.4.2.</span> <span class="toc-text">启动集群</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E6%B5%8B%E8%AF%95"><span class="toc-number">4.2.4.3.</span> <span class="toc-text">集群基本测试</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E5%8E%86%E5%8F%B2%E6%9C%8D%E5%8A%A1%E5%99%A8"><span class="toc-number">4.2.5.</span> <span class="toc-text">配置历史服务器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%97%A5%E5%BF%97%E7%9A%84%E8%81%9A%E9%9B%86"><span class="toc-number">4.2.6.</span> <span class="toc-text">配置日志的聚集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8-%E5%81%9C%E6%AD%A2%E6%96%B9%E5%BC%8F%E6%80%BB%E7%BB%93"><span class="toc-number">4.2.7.</span> <span class="toc-text">集群启动&#x2F;停止方式总结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%96%E5%86%99Hadoop%E9%9B%86%E7%BE%A4%E5%B8%B8%E7%94%A8%E8%84%9A%E6%9C%AC"><span class="toc-number">4.2.8.</span> <span class="toc-text">编写Hadoop集群常用脚本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E7%AB%AF%E5%8F%A3%E5%8F%B7%E8%AF%B4%E6%98%8E"><span class="toc-number">4.2.9.</span> <span class="toc-text">常用端口号说明</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9B%86%E7%BE%A4%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5"><span class="toc-number">4.2.10.</span> <span class="toc-text">集群时间同步</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98"><span class="toc-number">5.</span> <span class="toc-text">常见问题</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/560e8e48.html" title="博客美化"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic2.zhimg.com/v2-9964d2894516902605191817111ec781_r.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="博客美化"/></a><div class="content"><a class="title" href="/560e8e48.html" title="博客美化">博客美化</a><time datetime="2023-12-29T14:58:12.257Z" title="发表于 2023-12-29 22:58:12">2023-12-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/7ef7bbd4.html" title="LeetCode 118. 杨辉三角"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/202111011355394.png/lvxiaoyi" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="LeetCode 118. 杨辉三角"/></a><div class="content"><a class="title" href="/7ef7bbd4.html" title="LeetCode 118. 杨辉三角">LeetCode 118. 杨辉三角</a><time datetime="2023-03-19T14:25:59.394Z" title="发表于 2023-03-19 22:25:59">2023-03-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/82c8cab7.html" title="shell基础"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic2.zhimg.com/v2-9964d2894516902605191817111ec781_r.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="shell基础"/></a><div class="content"><a class="title" href="/82c8cab7.html" title="shell基础">shell基础</a><time datetime="2022-10-12T16:07:18.841Z" title="发表于 2022-10-13 00:07:18">2022-10-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/f1601c3e.html" title="单例模式"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/1002892-20180912131026735-781767905.png/lvxiaoyi" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="单例模式"/></a><div class="content"><a class="title" href="/f1601c3e.html" title="单例模式">单例模式</a><time datetime="2022-09-12T07:22:48.777Z" title="发表于 2022-09-12 15:22:48">2022-09-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/b15f0f1b.html" title="设计模式基础-1"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.lvxiaoyi.top/typora-img/image-20211012093705433.png/lvxiaoyi" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="设计模式基础-1"/></a><div class="content"><a class="title" href="/b15f0f1b.html" title="设计模式基础-1">设计模式基础-1</a><time datetime="2022-09-12T07:22:48.777Z" title="发表于 2022-09-12 15:22:48">2022-09-12</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://img.lvxiaoyi.top/typora-img/image-20211028174657424.png/lvxiaoyi')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By lvxiaoyi</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"></div><canvas id="universe"></canvas><script defer src="/js/lvxiaoyi.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>